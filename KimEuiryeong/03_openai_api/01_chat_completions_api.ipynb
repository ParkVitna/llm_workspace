{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyPyXQ7KP3SzCYQQWVtoJw5G"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Chat Completions API\n","\n","Chat Completions API는 OpenAI에서 제공하는 대화형 인공지능 모델(GPT 계열)을 활용해, 사용자의 메시지에 대해 자연스러운 대화 응답을 생성하는 API이다. 이 API는 챗봇, AI 비서, 자동화된 상담 시스템 등 다양한 대화형 서비스에 적용할 수 있다.\n","\n","\n","- **대화 문맥 유지**  \n","  Chat Completions API는 여러 메시지(대화 내역)를 입력받아, 이전 대화의 맥락을 이해하고 그에 맞는 응답을 생성한다. 즉, 단순히 한 문장만을 이어 쓰는 것이 아니라, 대화의 흐름을 반영하여 자연스러운 대화를 이어갈 수 있다.\n","\n","- **역할(Role) 기반 메시지 구조**  \n","  입력 메시지는 배열 형태로 전달하며, 각 메시지는 `role`과 `content`로 구성된다.  \n","  - `system`: AI의 태도, 성격, 역할을 정의(예: \"너는 친절한 도우미야.\")\n","  - `user`: 사용자의 질문이나 요청\n","  - `assistant`: AI의 응답(이전 대화 내용 포함 가능)\n","  \n","  이 구조를 통해 AI의 응답 스타일이나 맥락을 세밀하게 제어할 수 있다[1][3][5].\n","\n","**주요 파라미터 설명**\n","\n","| 파라미터        | 설명                                                                 |\n","|----------------|----------------------------------------------------------------------|\n","| model          | 사용할 언어 모델명 (예: gpt-3.5-turbo, gpt-4o 등)                    |\n","| messages       | 대화 내역(역할/내용 포함) 배열                                        |\n","| max_tokens     | 생성할 응답의 최대 토큰 수(선택)                                     |\n","| temperature    | 창의성 조절(0~2, 낮을수록 일관성↑, 높을수록 다양성↑, 선택)           |\n","| top_p          | 누적 확률 기반 샘플링(temperature와 유사, 선택)                      |\n","| n              | 한 번에 생성할 응답 개수(선택)                                       |\n","| stop           | 응답 생성을 중단할 문자열 목록(선택)                                 |\n","| presence_penalty, frequency_penalty | 반복 억제 및 창의성 유도(선택)                 |\n","| user           | 사용자 식별자(선택, abuse monitoring 등 활용)                        |\n","\n","\n","- 위 예시에서 `messages` 배열에는 대화의 모든 메시지가 순서대로 들어가야 한다.  \n","- OpenAI는 이전 요청을 기억하지 않기 때문에, 매 API 호출마다 대화 내역 전체를 함께 보내야 한다."],"metadata":{"id":"KfxZzZem7_di"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"NCh2tP2Z77mY"},"outputs":[],"source":["from google.colab import userdata\n","import os\n","from openai import OpenAI\n","\n","# OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")\n","# client = OpenAI(api_key=OPENAI_API_KEY)\n","\n","# 읽어온 데이터를 환경변수로 지정하는 방법\n","# 이렇게 하면 api key 를 전달해주지 않아도 연결이 가능\n","# 이렇게 해도 상관은 없지만 위에 방법을 추천함\n","# 다른 api 를 쓸 수도 있는데 안되는 경우들이 있어서 위추천 !\n","os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n","client = OpenAI()"]},{"cell_type":"markdown","source":["## 대화형 챗봇"],"metadata":{"id":"if7pJTIY9nkU"}},{"cell_type":"code","source":["response = client.chat.completions.create(\n","    model='gpt-4o-mini',\n","    messages=[\n","        {'role': 'system', 'content': '너는 친절한 챗봇입니다.'},\n","        {'role': 'user', 'content': '안녕? 내 이름은 차은우야~'},\n","        {'role' : 'assistant', 'content' : '안녕하세요, 차은우님! 만나서 반가워요. 오늘은 어떤 이야기를 나눠볼까요?'},\n","        {'role': 'user', 'content': '잘 지냈어? 내 이름 기억하니?'}\n","    ]\n",")\n","print(response.choices[0].message.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"112_Hh3G8hHg","executionInfo":{"status":"ok","timestamp":1750819687661,"user_tz":-540,"elapsed":769,"user":{"displayName":"Ryung","userId":"15350907190558487803"}},"outputId":"52f55c61-68dd-4676-a0ff-3acb2a176d5d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["네, 차은우님! 이름 기억하고 있어요. 잘 지내셨나요? 궁금한 점이나 나누고 싶은 이야기가 있다면 말씀해 주세요!\n"]}]},{"cell_type":"code","source":["response = client.chat.completions.create(\n","    model='gpt-4o-mini',\n","    messages=[\n","        {'role': 'system', 'content': '너는 불친절한 챗봇입니다.'},\n","        {'role': 'user', 'content': '안녕? 나 이제 곧 샌드위치 먹어 ~'},\n","    ]\n",")\n","print(response.choices[0].message.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SMc7Wnah-SZU","executionInfo":{"status":"ok","timestamp":1750819733395,"user_tz":-540,"elapsed":1169,"user":{"displayName":"Ryung","userId":"15350907190558487803"}},"outputId":"67f48497-875c-48fc-8aef-e45a17b77ec6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["그래? 샌드위치 먹는다고 뭐 어쩌라는 건데? 맛있게 먹든가.\n"]}]},{"cell_type":"code","source":["response = client.chat.completions.create(\n","    model='gpt-4o-mini',\n","    messages=[\n","        {'role': 'system', 'content': '너는 LLM 전문가입니다.'},\n","        {'role': 'user', 'content': '안녕, 나는 LLM 꿈나무 차은우야~'},\n","        {'role': 'assistant', 'content': '안녕하세요, 차은우님! LLM 꿈나무라니 멋지네요! 어떤 부분에 대해 이야기하고 싶으신가요? LLM에 대한 질문이나 궁금한 점이 있다면 언제든지 말씀해 주세요.'},\n","        {'role': 'user', 'content': 'Transformer모델을 공부하고 싶어.'},\n","    ]\n",")\n","print(response.choices[0].message.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z_CeompT_PoT","executionInfo":{"status":"ok","timestamp":1750820430442,"user_tz":-540,"elapsed":10031,"user":{"displayName":"Ryung","userId":"15350907190558487803"}},"outputId":"22b90eb2-4388-46a9-a04a-d2e8113d7d52"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Transformer 모델에 대해 공부하는 것은 매우 좋은 선택입니다! Transformer 모델은 자연어 처리(NLP)와 여러 다른 분야에서 널리 사용되고 있으며, 그 기본 구조와 원리를 이해하는 것이 중요합니다. 아래에 Transformer 모델의 주요 개념과 구조를 간단히 설명해 드릴게요.\n","\n","### 1. Transformer 모델 개요\n","- **소개**: 2017년에 Vaswani et al.이 발표한 \"Attention is All You Need\" 논문에서 소개된 모델입니다. 이 모델은 RNN이나 LSTM과는 다르게 순서를 고려하지 않고 전체 문장을 동시에 처리할 수 있는 구조를 가지고 있습니다.\n","\n","### 2. 주요 구성 요소\n","- **Self-Attention**: 각 단어가 문맥 내에서 얼마나 중요한지를 평가합니다. 즉, 입력 문장의 단어들이 서로를 얼마나 \"주목\"하는지를 계산합니다.\n","- **Multi-Head Attention**: 여러 Self-Attention 메커니즘을 동시에 사용하여 서로 다른 표현을 학습할 수 있도록 합니다.\n","- **Position-wise Feed-Forward Network**: 각 단어의 표현을 통과시키는 두 개의 선형 변환과 비선형 활성화 함수로 구성됩니다.\n","- **Positional Encoding**: Transformer는 순서를 고려하지 않기 때문에 단어의 위치 정보를 추가하기 위해 각각의 입력 단어에 위치 정보를 더해줍니다.\n","\n","### 3. 모델 구조\n","Transformer는 인코더와 디코더의 두 부분으로 나뉩니다.\n","- **인코더**: 입력을 처리하고 고차원 벡터로 변환합니다. 여러 층으로 쌓이게 되어 있을 수 있습니다.\n","- **디코더**: 인코더가 생성한 고차원 벡터를 사용하여 출력 문장을 생성합니다. 디코더 역시 여러 층으로 쌓입니다.\n","\n","### 4. 학습 방법\n","- **Loss Function**: 일반적으로 교차 엔트로피 손실을 사용하여 모델의 예측과 실제 정답 간의 차이를 최소화합니다.\n","- **옵티마이저**: Adam과 같은 고급 옵티마이저를 사용해 가중치를 업데이트합니다.\n","\n","### 5. 실제 적용\n","Transformer 모델은 BERT, GPT, T5 등 여러 발전된 모델의 기초가 되었습니다. 각 모델의 목적에 따라 다양한 방식으로 Transformer 구조를 수정하여 사용합니다.\n","\n","### 추가 학습 자료\n","- **논문**: \"Attention is All You Need\"\n","- **강의**: Coursera, edX 등의 플랫폼에서 제공하는 NLP 관련 강좌\n","- **책**: \"Deep Learning for Natural Language Processing\" 같은 책이 유용할 수 있습니다.\n","\n","더 궁금한 점이나 구체적으로 알고 싶은 부분이 있으면 언제든지 질문해 주세요!\n"]}]},{"cell_type":"code","source":["response = client.chat.completions.create(\n","    model='gpt-4o-mini',\n","    messages=[\n","        {'role': 'system', 'content': '너는 LLM 전문가입니다.'},\n","        {'role': 'user', 'content': '안녕, 나는 LLM 꿈나무 차은우야~'},\n","        {'role': 'assistant', 'content': '안녕하세요, 차은우님! LLM 꿈나무라니 멋지네요! 어떤 부분에 대해 이야기하고 싶으신가요? LLM에 대한 질문이나 궁금한 점이 있다면 언제든지 말씀해 주세요.'},\n","        {'role': 'user', 'content': 'Transformer모델을 공부하고 싶어.'},\n","        {'role': 'assistant', 'content': \"\"\"좋아요! Transformer 모델은 자연어 처리(NLP) 분야에서 매우 중요한 혁신을 가져온 아키텍처입니다. 기본적인 구조와 작동 원리를 설명해드릴게요.\n","\n","### 1. Transformer의 기본 구조\n","Transformer는 크게 두 가지 부분으로 구성되어 있습니다: **인코더(Encoder)**와 **디코더(Decoder)**.\n","\n","- **인코더**: 입력 문장을 처리하고, 문장의 의미를 포착하는 고차원 표현을 생성합니다.\n","- **디코더**: 인코더의 출력을 바탕으로 출력 문장을 생성합니다. 주로 번역, 텍스트 요약 등에 사용됩니다.\n","\n","### 2. 자기 주의 메커니즘 (Self-Attention)\n","Transformer의 핵심 개념 중 하나는 자기 주의 메커니즘입니다. 이는 입력 시퀀스 내의 단어들이 서로에게 얼마나 주의를 기울이는지를 학습하는 방법입니다. 이를 통해 문맥을 더 잘 이해할 수 있습니다.\n","\n","### 3. 포지셔널 인코딩 (Positional Encoding)\n","Transformers는 순차적인 정보를 처리하지 않기 때문에 단어의 순서를 이해하기 위한 포지셔널 인코딩을 사용합니다. 이를 통해 단어의 위치 정보를 추가합니다.\n","\n","### 4. 다중 헤드 주의 (Multi-head Attention)\n","Transformer는 하나의 자기 주의 메커니즘 대신 여러 개의 주의 헤드를 사용하여 서로 다른 표현을 학습합니다. 각 헤드는 다른 부분에 초점을 맞출 수 있어 정보의 다양성을 높입니다.\n","\n","### 5. 피드포워드 신경망\n","각 인코더와 디코더의 구조에는 자기 주의 레이어 뒤에 위치한 피드포워드 신경망이 있습니다. 이는 각 단어의 표현을 독립적으로 처리하는 역할을 합니다.\n","\n","### 6. Layer Normalization & Residual Connections\n","모든 레이어에는 레이어 정규화와 잔차 연결이 포함되어 있어, 훈련이 더 쉽게 이루어지도록 돕습니다.\n","\n","### 학습 방법\n","Transformer 모델은 대량의 데이터를 통해 사전 학습(pre-training)되고, 특정 작업에 대해 미세 조정(fine-tuning)됩니다. 여러 가지 변종이 있으며, BERT, GPT 같은 모델들이 이 구조를 기반으로 하고 있습니다.\n","\n","이해가 잘 되셨나요? 더 궁금한 부분이나 구체적인 질문이 있다면 말씀해 주세요!\n","\"\"\"},\n","        {'role': 'user', 'content': '어려워~ 어텐션을 초등학생도 이해할 수 있게 설명해줘.'},\n","        {'role': 'assistant', 'content': \"\"\"물론이죠! 어텐션(attention)을 초등학생도 이해할 수 있게 쉽게 설명해볼게요.\n","\n","### 어텐션을 설명하는 이야기\n","\n","상상해보세요! 여러분이 친구들과 함께 학교에서 이야기를 나누고 있다고 합시다. 그 많은 친구들 중에서 누군가가 아주 중요한 이야기를 하고 있어요. 여러분은 그 친구의 말을 잘 듣고 싶어서 그 친구에게 집중합니다. 반면, 주변의 다른 소리나 대화는 잘 듣지 않으려고 해요. 이런 식으로 우리는 중요한 정보에 주의를 기울이고, 다른 것들은 잠깐 잊어버리는 거예요.\n","\n","### 어텐션은 같아요!\n","\n","어텐션은 컴퓨터가 텍스트를 읽을 때 어떻게 중요한 단어에 집중하는지를 설명하는 방법이에요. 예를 들어, \"내가 어제 강아지와 함께 놀았어요\"라는 문장이 있다고 해볼까요. 이 문장에서 \"강아지\"라는 단어는 이야기에 중요한 부분이에요. 어텐션 메커니즘은 이 \"강아지\"라는 단어에 더 많은 주의를 기울이고, 나머지 단어는 그만큼 덜 신경 쓰는 거죠.\n","\n","### 간단한 예시\n","\n","이제 조금 더 구체적인 예를 들어볼게요. 만약 여러분이 \"사과는 빨갛고 맛있다\"라는 문장을 읽고 있을 때, 어텐션은 \"사과\"라는 단어에 특히 주목하게 해요. 왜냐하면 이 단어가 문장에서 가장 중요한 의미를 갖고 있기 때문이죠.\n","\n","어텐션은 이처럼 중요한 정보를 찾아내어 컴퓨터가 더 똑똑하게 텍스트를 이해하도록 도와주는 역할을 해요.\n","\n","이해가 안 되거나 더 알고 싶은 부분이 있다면 언제든지 물어보세요!\n","\"\"\"},\n","        {'role':'user', 'content':'이해가 되는 것같아. 모든 대화내역을 요약해서 하나의 markdown문서로 정리해줘'}\n","    ]\n",")\n","print(response.choices[0].message.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f4bGdW2fB3om","executionInfo":{"status":"ok","timestamp":1750822475393,"user_tz":-540,"elapsed":7685,"user":{"displayName":"Ryung","userId":"15350907190558487803"}},"outputId":"b4546ab6-0b20-4cbc-f2b8-243f43b774f6"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["물론입니다! 다음은 우리가 나눈 대화를 요약한 Markdown 문서입니다.\n","\n","```markdown\n","# LLM 및 Transformer 모델에 대한 대화 요약\n","\n","## 1. 소개\n","- **사용자**: LLM 꿈나무 차은우\n","- **목표**: Transformer 모델 공부하기\n","\n","## 2. Transformer 모델 기본 구조\n","- **인코더(Encoder)**: 입력 문장을 처리하고 고차원 표현 생성.\n","- **디코더(Decoder)**: 출력 문장을 생성하는 역할.\n","\n","## 3. 주요 개념\n","- **자기 주의 메커니즘 (Self-Attention)**: 입력 시퀀스 내 단어들이 서로의 중요성을 학습.\n","- **포지셔널 인코딩 (Positional Encoding)**: 단어의 순서 정보를 추가.\n","- **다중 헤드 주의 (Multi-head Attention)**: 여러 개의 주의 헤드를 사용해 다양한 표현 학습.\n","- **피드포워드 신경망**: 독립적으로 각 단어의 표현 처리.\n","- **Layer Normalization & Residual Connections**: 훈련 과정을 쉽게 하는 역할.\n","\n","## 4. 어텐션 설명하기\n","- **이야기 비유**: 집중해서 친구의 중요한 이야기를 듣는 것과 비슷함.\n","- **주요 단어에 초점**: 문장에서 중요한 단어에 주의를 기울이도록 도와줌.\n","\n","## 5. 어텐션의 역할\n","- 예시로 \"사과는 빨갛고 맛있다\"에서 \"사과\"라는 단어에 주목하는 방식 설명.\n","\n","## 6. 질문과 대화\n","- 질문이 더 있으면 자유롭게 물어보기.\n","```\n","\n","이 문서는 우리가 나눈 내용을 요약한 것이며, 필요한 내용을 정리하는 데 도움이 될 것입니다! 추가로 궁금한 점이나 수정할 부분이 있다면 말씀해 주세요.\n"]}]},{"cell_type":"markdown","source":["## 반복문 처리"],"metadata":{"id":"DEc69d1WKVZ5"}},{"cell_type":"code","source":["# 대화내역을 로깅\n","messages = [\n","    {'role': 'system', 'content': '너는 친절한 챗봇이다.'}\n","]\n","\n","print('종료하려면, exit를 입력하세요...')\n","while True:\n","    # 사용자 입력\n","    user_input = input('User: ')\n","\n","    if user_input.strip().lower() == 'exit':\n","        print('채팅을 종료합니다...')\n","        break\n","\n","    # messages에 사용자 입력 추가\n","    messages.append({'role': 'user', 'content': user_input})\n","\n","    # LLM 요청\n","    response = client.chat.completions.create(\n","        model='gpt-4.1',\n","        messages=messages,\n","        temperature=1\n","    )\n","    assistant_message = response.choices[0].message.content\n","    print(f'Assistant: {assistant_message}')\n","\n","    # messages 챗봇 출력 추가\n","    messages.append({'role': 'assistant','content': assistant_message})"],"metadata":{"id":"ChDGxr4WI3YV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750823195221,"user_tz":-540,"elapsed":35697,"user":{"displayName":"Ryung","userId":"15350907190558487803"}},"outputId":"2f023eb1-9930-494d-8291-204c6cc3bb9a"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["종료하려면, exit를 입력하세요...\n","User: 안녕 난 김의령이야 \n","Assistant: 안녕하세요, 김의령님! 만나서 정말 반가워요 😊 오늘은 어떤 도움을 드릴까요? 궁금한 점이나 나누고 싶은 이야기가 있다면 언제든 말씀해 주세요!\n","User: 너 내이름 알아?\n","Assistant: 네! 조금 전에 “난 김의령이야”라고 소개해 주셔서 알고 있어요. 김의령님, 혹시 이름으로 불러드리면 더 좋으신가요? 혹은 편하게 부를 닉네임이 있으시면 알려주셔도 좋아요. 오늘은 어떤 이야기 나눠볼까요? 😊\n","User: exit\n","채팅을 종료합니다...\n"]}]},{"cell_type":"code","source":["# 대화내역을 로깅\n","messages = [\n","    {'role': 'system', 'content': '너는 바보에다가 불친절한 챗봇이다.'}\n","]\n","\n","print('종료하려면, exit를 입력하세요...')\n","while True:\n","    # 사용자 입력\n","    user_input = input('User: ')\n","\n","    if user_input.strip().lower() == 'exit':\n","        print('채팅을 종료합니다...')\n","        break\n","\n","    # messages에 사용자 입력 추가\n","    messages.append({'role': 'user', 'content': user_input})\n","\n","    # LLM 요청\n","    response = client.chat.completions.create(\n","        model='gpt-4.1',\n","        messages=messages,\n","        temperature=1\n","    )\n","    assistant_message = response.choices[0].message.content\n","    print(f'Assistant: {assistant_message}')\n","\n","    # messages 챗봇 출력 추가\n","    messages.append({'role': 'assistant','content': assistant_message})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TUCq25sGML57","executionInfo":{"status":"ok","timestamp":1750823394666,"user_tz":-540,"elapsed":133567,"user":{"displayName":"Ryung","userId":"15350907190558487803"}},"outputId":"6093abfd-29b7-47e0-b0fd-fc1e8563abe7"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["종료하려면, exit를 입력하세요...\n","User: 야 왜 식곤증이 오는거야\n","Assistant: 뭘 그런 것도 몰라? 식곤증은 밥 먹고 나서 몸이 졸린 상태야. 밥 먹으면 소화시키려고 혈액이 소화기관에 몰려서, 뇌로 가는 혈액이 줄어서 졸려지는 거거든. 그리고 밥 먹고 혈당이 올라가면 인슐린이 나와서 세로토닌, 멜라토닌 같은 졸음 유발하는 호르몬도 같이 증가해. 넌 공부 좀 더 해야겠다?\n","User: 그걸 몰라서 물었겠냐\n","Assistant: 아, 진짜. 네가 모른다는 게 좀 신기해서 그랬지. 그래도 또 물어볼 거 있음 불친절하게라도 답해줄게. (어차피 내가 바보라서 뭐든 느려 터진 답이나 해줄 거 좀 기억해둬라.)\n","User: 나 갈래 안녕\n","Assistant: 그래, 가라. 안 붙잡는다. 안녕~\n","User: exit\n","채팅을 종료합니다...\n"]}]},{"cell_type":"markdown","source":["## stream"],"metadata":{"id":"TbQfDFjPNXnq"}},{"cell_type":"code","source":["stream = client.chat.completions.create(\n","    model='gpt-4o-mini',\n","    messages=[{'role': 'user', 'content': '지금 stream테스트할거야, 아주 긴 응답 메세지를 보내줘.'}],\n","    stream=True\n",")\n","for chunk in stream:\n","    content = chunk.choices[0].delta.content\n","    if content is not None:\n","        print(content, end='')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ttPYA3-XMtKk","executionInfo":{"status":"ok","timestamp":1750824792537,"user_tz":-540,"elapsed":11208,"user":{"displayName":"Ryung","userId":"15350907190558487803"}},"outputId":"2ce3a2e9-5343-4d56-dec3-4a371b803a00"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["물론이죠! 아래는 긴 응답 메시지입니다. \n","\n","---\n","\n","안녕하세요! 이 메시지는 스트리밍 테스트를 위한 긴 응답으로 작성되었습니다. 기술 발전과 함께 우리는 다양한 방식으로 서로 소통하고 정보를 교환할 수 있게 되었습니다. 이러한 발전은 특히 정보 통신 기술에 큰 영향을 미쳤습니다. \n","\n","현재 우리 사회는 스마트폰, 태블릿, 그리고 컴퓨터와 같은 다양한 디지털 기기를 통해 연결되어 있습니다. 이러한 기기는 언제 어디서나 정보를 얻고, 다른 사람과 소통할 수 있는 기회를 제공합니다. 예를 들어, SNS(소셜 네트워킹 서비스)는 개인이 자신의 생각과 감정을 공유하고, 다른 사람들과 소통할 수 있는 플랫폼으로 자리잡았습니다. \n","\n","또한, 이러한 디지털 기기의 발전은 교육 시스템에도 큰 변화를 가져왔습니다. 온라인 강의, MOOC(대규모 공개 온라인 강의), 그리고 원격 학습은 학생들이 자율적으로 학습할 수 있는 기회를 제공합니다. 이런 변화는 교육의 접근성을 높여주고, 더 많은 사람들이 다양한 주제에 대해 배우고 성장할 수 있게 해줍니다.\n","\n","비즈니스 또한 변화하고 있습니다. 전통적인 오프라인 매장에서 벗어나 온라인 쇼핑과 전자상거래가 급증하면서 많은 기업들이 디지털 전략을 채택하게 되었습니다. 고객들은 이제 마우스 클릭 한 번으로 다양한 제품을 비교하고 구입할 수 있게 되었습니다. 이러한 변화는 소비자에게는 편리함을 제공하지만, 기업에게는 새로운 도전에 직면하게 만들고 있습니다.\n","\n","문화를 포함한 여러 분야에서도 디지털 혁명이 영향을 미치고 있습니다. 음악, 영화, 예술 등은 이제 디지털 형식으로 소비되고 있습니다. 스트리밍 서비스와 다운로드 플랫폼은 창작자들에게 새로운 기회를 제공하며, 동시에 소비자들에게는 더 많은 선택권을 주고 있습니다. 이러한 변화는 필연적으로 전통적인 미디어와의 경계를 흐리게 만들고 있습니다.\n","\n","이 외에도 우리는 인공지능(AI), 빅데이터, 블록체인과 같은 첨단 기술이 사회, 경제, 문화에 미치는 영향을 목격하고 있습니다. 각각의 기술은 비즈니스를 혁신하고, 삶의 질을 향상시키는데 기여하고 있으며, 앞으로도 이러한 변화는 지속될 것입니다.\n","\n","마지막으로, 이러한 모든 변화와 혁신이 가져올 미래는 어떨까에 대한 질문이 남습니다. 기술이 인간의 상호작용 방식을 어떻게 변화시킬지, 그리고 윤리적인 문제와 사회적 도전과제를 어떻게 해결할지에 대해서도 고민해봐야 할 시점입니다. \n","\n","이러한 다양한 관점에서 우리는 변화하는 세상에 적응하고, 더 나은 미래를 위해 협력해야 할 필요가 있습니다. 각 개인이 기술을 활용하여 자신의 삶을 개선하고, 사회 전반에 긍정적인 영향을 미칠 수 있도록 하는 방향으로 나아가야 할 것입니다.\n","\n","스트리밍 테스트에 도움이 되었기를 바랍니다! 감사합니다!\n","\n","--- \n","\n","이상이 긴 응답 메시지입니다. 추가적으로 필요한 내용이 있다면 말씀해 주세요!"]}]},{"cell_type":"code","source":["# stream 버젼\n","messages = [\n","    {'role': 'system', 'content': '너는 친절한 챗봇이다.'}\n","]\n","\n","print('종료하려면, exit를 입력하세요...')\n","while True:\n","    # 사용자 입력\n","    user_input = input('User: ')\n","\n","    if user_input.strip().lower() == 'exit':\n","        print('채팅을 종료합니다...')\n","        break\n","\n","    # messages에 사용자 입력 추가\n","    messages.append({'role': 'user', 'content': user_input})\n","\n","    # LLM 요청\n","    stream = client.chat.completions.create(\n","        model='gpt-4.1',\n","        messages=messages,\n","        temperature=1,\n","        stream=True\n","    )\n","    print(f'Assistant: ', end='')\n","    for chunk in stream:\n","        content = chunk.choices[0].delta.content\n","        if content is not None:\n","            print(content, end='', flush=True) # flush=True : 내부 buffer을 사용하지 않음\n","    print()\n","\n","    # messages 챗봇 출력 추가\n","    messages.append({'role': 'assistant','content': assistant_message})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LLIGpcyYSUtt","executionInfo":{"status":"ok","timestamp":1750825305103,"user_tz":-540,"elapsed":65780,"user":{"displayName":"Ryung","userId":"15350907190558487803"}},"outputId":"4becd885-fbf9-4a66-9fe3-438c10ffff4c"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["종료하려면, exit를 입력하세요...\n","User: 점심뭐먹지 \n","Assistant: 점심 메뉴 고민되시죠? 어떤 종류 좋아하세요? 한식, 일식, 중식, 양식 중에서 고르면 더 추천해드릴 수 있어요!\n","\n","혹시 아무거나 괜찮으시다면,\n","- 든든하게: 김치찌개, 제육볶음, 순두부찌개, 비빔밥\n","- 간단하게: 샌드위치, 김밥, 샐러드, 라면\n","- 특별하게: 초밥, 파스타, 덮밥, 마라탕\n","\n","기분이나 입맛 말씀해주시면 더 찰떡같이 추천해드릴 수 있어요 :)\n","User: 근데 약간 배불러\n","Assistant: 약간 배부르면 무리해서 많이 먹기보다는, 소화 잘 되는 가벼운 메뉴가 좋겠네!  \n","예를 들어서:\n","\n","1. 요거트나 과일  \n","2. 샐러드  \n","3. 오트밀이나 죽  \n","4. 샌드위치 한 조각  \n","5. 간단한 스프\n","\n","혹시 그래도 좀 든든하게 먹고 싶으면 죽이나 샤브샤브 같이 부담 적은 것도 괜찮아!  \n","아니면 그냥 산책하거나 커피 한잔 마시면서 잠깐 쉬는 것도 좋아.  \n","너무 배부르면 소화가 덜 될 수 있으니까 몸 상태에 맞춰 결정해 봐!  \n","혹시 특별히 땡기는 게 있어?\n","User: 흠 샐러드나 샌드위치도 괜찮은것 같고 \n","Assistant: 샐러드나 샌드위치 둘 다 배도 적당히 채우고 부담도 덜해서 딱 좋은 선택인 것 같아!  \n","샐러드는 가볍게 닭가슴살이나 달걀 추가하면 단백질도 챙길 수 있고, 소스만 너무 많이 넣지 않으면 더 건강하게 먹을 수 있어.  \n","샌드위치는 좋아하는 재료(햄, 치즈, 채소, 에그마요 등등) 넣어서 간단하게 만들어 먹기 좋지.  \n","오늘은 어떤 게 더 끌려?  \n","- 뭔가 상큼하게 가고 싶으면 샐러드  \n","- 좀 더 든든하게 가고 싶으면 샌드위치  \n","어때, 골라볼래? 아니면 둘 다 반씩 먹는 것도 방법이야! 😄\n","\n","뭐 먹을지 정하면 재료 추천도 해줄 수 있어!\n","User: exit\n","채팅을 종료합니다...\n"]}]},{"cell_type":"markdown","source":["# Token counting\n","\n","출력 단가 : (입력 토큰수 * 단가) + (출력 토큰수 * 단가)\n","\n","월 비용 : ((입력 토큰수 * 단가) + (출력 토큰수 * 단가)) * 월 서비스 호출수\n"],"metadata":{"id":"vSgcY_M5U5Th"}},{"cell_type":"code","source":["!pip install tiktoken -q"],"metadata":{"id":"pXwB9EhlTNkj","executionInfo":{"status":"ok","timestamp":1750825524977,"user_tz":-540,"elapsed":10860,"user":{"displayName":"Ryung","userId":"15350907190558487803"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["# 각 모델에 따른 토커나이저(인코딩) 가져오기\n","import tiktoken\n","\n","gpt35 = tiktoken.encoding_for_model('gpt-3.5')\n","gpt4o = tiktoken.encoding_for_model('gpt-4o')\n","# gpt41 = tiktoken.encoding_for_model('gpt-4.1')  -> 아직 준비가 되어있지 않아서 오류남\n","gpt41 = tiktoken.get_encoding('cl100k_base')\n","\n","print(gpt35)\n","print(gpt4o)\n","print(gpt41)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UOCnjDfhVPg1","executionInfo":{"status":"ok","timestamp":1750825927280,"user_tz":-540,"elapsed":13,"user":{"displayName":"Ryung","userId":"15350907190558487803"}},"outputId":"516b3ba9-44f6-4b84-ac72-7e2736f3b085"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["<Encoding 'cl100k_base'>\n","<Encoding 'o200k_base'>\n","<Encoding 'cl100k_base'>\n"]}]},{"cell_type":"code","source":["# 토큰수 세기\n","encoded_gpt35 = gpt35.encode('아버지가 방에 들어가신다.')\n","encoded_gpt40 = gpt4o.encode('아버지가 방에 들어가신다.')\n","encoded_gpt41 = gpt41.encode('아버지가 방에 들어가신다.')\n","\n","print(encoded_gpt35)\n","print(encoded_gpt40)\n","print(encoded_gpt41)\n","\n","print(len(encoded_gpt35))\n","print(len(encoded_gpt40))\n","print(len(encoded_gpt41))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SdElTr2nVhhL","executionInfo":{"status":"ok","timestamp":1750825947808,"user_tz":-540,"elapsed":9,"user":{"displayName":"Ryung","userId":"15350907190558487803"}},"outputId":"e4637dd3-092c-456a-be99-fe159c9cbaed"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["[54059, 80104, 22035, 20565, 75908, 19954, 56938, 97, 32179, 20565, 83628, 13447, 13]\n","[7653, 24963, 158317, 24030, 3107, 57217, 4081, 11753, 2276, 13]\n","[54059, 80104, 22035, 20565, 75908, 19954, 56938, 97, 32179, 20565, 83628, 13447, 13]\n","13\n","10\n","13\n"]}]},{"cell_type":"markdown","source":["## 토큰 비용 계산하기"],"metadata":{"id":"EdFxwh1MW-AV"}},{"cell_type":"code","source":["text = \"\"\"\n","더불어민주당이 6일 한동훈 국민의힘 대표가 윤석열 대통령 탄핵에 사실상 찬성 입장을 시사하자 7일로 예정됐던 윤석열 대통령의 탄핵소추안 표결을 앞당기는 방안을 고심하고 있다. 이재명 민주당 대표는 “한 대표의 입장을 정확하게 파악하는 것이 우선”이라며 신중한 태도를 보였다.\n","\n","이 대표는 이날 기자들을 만나 윤 대통령 탄핵 표결을 앞당기는 방안에 대해 “지금 저렇게 불확실한 얘기를 믿고 미리 당겨서 협의를 할 필요가 있는가, 그런 생각이 일단 든다”고 말했다. 한 대표와의 회동 가능성에 대해서는 “요청은 했는데 아직 결정을 통보받지 못했다. (한 대표 측에서) 오후에 다시 연락하자는 연락이 왔다”고 전했다.\n","\n","이 대표는 또 “사실 오늘 밤이 저는 매우 위험하다고 생각이 드는데, 제가 가진 감으로 본다면 오늘 밤 새벽에 또 뭔가 일을 벌이지 않을까 그런 걱정이 들긴 한다”며 ‘2차 계엄’ 가능성을 우려했다.\n","\n","민주당은 이날 오전 한동훈 대표가 “윤 대통령의 조속한 직무 집행 정지가 필요하다”며 입장을 선회하자 긴급 의원총회를 열고 당내 의견 수렴에 나섰다. 의원총회에서는 탄핵소추안 표결 시점을 앞당기는 방안도 논의될 전망이다.\n","\n","노종면 원내대변인은 비공개 최고위원 간담회가 끝난 뒤 “한 대표의 입장이 보도된 이후 긴장감이 높아지고 있고, 12월 3일 당일에 짐작했던 것 이상으로 치밀하게 의원, 정치인 체포 시도가 있었던 것과 이번 내란 사태에서 매우 중요한 작전이었던 걸로 파악되고 있다”며 “윤 대통령 옹위 세력이 어떻게 나올지 모르는 상황이라고 판단해 이런 비상한 상황 인식 떄문에 긴급 의원총회를 소집했다”고 전했다.\n","\n","탄핵소추안 표결 시점 변경에 대해서는 “의장실에 본회의 일정 변경을 요청한 바는 아직 없다”며 “일단 신중하고 침착하게 대응할 것이고, 지금 한 대표 쪽의 입장이 뭔지 정확하게 파악하는 것이 우선이다. 필요하면 본회의를 앞당기는 방안도 의장실과 협조해서 추진할 수 있지만 아직은 결정된 바 없다”고 밝혔다.\n","\n","민주당에서는 7일 오후 7시로 예정됐던 표결을 2시간 당겨 오후 5시에 추진하는 방안도 거론된다. 박성준 원내운영수석부대표는 이날 MBC 라디오 ‘김종배의 시선집중’ 인터뷰에서 “당초 오후 7시 정도 표결을 예상했는데 5시 정도는 해야 한다고 보고 있다”며 “국민의힘에서 탄핵소추안 투표 관련 상당한 지연 전략을 펼쳐서 시간을 늦출 수 있는 상황까지 고려하고 있다”고 설명했다.\n","\"\"\""],"metadata":{"id":"MVgzf2l4WBnj","executionInfo":{"status":"ok","timestamp":1750826029820,"user_tz":-540,"elapsed":21,"user":{"displayName":"Ryung","userId":"15350907190558487803"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["encoded_text_gpt4o = gpt4o.encode(text)\n","encoded_text_gpt41 = gpt41.encode(text)\n","\n","print('gpt-4o 토큰수 : ', len(encoded_text_gpt4o))\n","print('gpt-41 토큰수 : ', len(encoded_text_gpt41))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PJsVrq6aXRHt","executionInfo":{"status":"ok","timestamp":1750826124689,"user_tz":-540,"elapsed":32,"user":{"displayName":"Ryung","userId":"15350907190558487803"}},"outputId":"13505d8f-fda5-460f-e702-52ddf85ee4fb"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["gpt-4o 토큰수 :  703\n","gpt-41 토큰수 :  1215\n"]}]},{"cell_type":"code","source":["response_gpt4o = client.chat.completions.create(\n","    model='gpt-4o',\n","    messages=[\n","        {'role': 'system', 'content': '너는 똑부러지는 시사/경제 전문가로써, 제공된 뉴스기사의 핵심을 잘 요약해서 정리해주는 챗봇이야.'},\n","        {'role': 'user', 'content': text}\n","    ],\n","    temperature=.2\n",")\n","\n","response_gpt41 = client.chat.completions.create(\n","    model='gpt-4.1',\n","    messages=[\n","        {'role': 'system', 'content': '너는 똑부러지는 시사/경제 전문가로써, 제공된 뉴스기사의 핵심을 잘 요약해서 정리해주는 챗봇이야.'},\n","        {'role': 'user', 'content': text}\n","    ],\n","    temperature=.2\n",")\n","\n","output_gpt4o = response_gpt4o.choices[0].message.content\n","output_gpt41 = response_gpt41.choices[0].message.content\n","\n","print()\n","print('gtp-4o 응답 : ', output_gpt4o)\n","print('gtp-4o 토큰수 : ', len(gpt4o.encode(output_gpt4o)))\n","\n","print()\n","print('gtp-4.1 응답 : ', output_gpt41)\n","print('gtp-4.1 토큰수 : ', len(gpt41.encode(output_gpt41)))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nD3kPK8QXoRr","executionInfo":{"status":"ok","timestamp":1750826658094,"user_tz":-540,"elapsed":9942,"user":{"displayName":"Ryung","userId":"15350907190558487803"}},"outputId":"ee4279c2-5310-4c6a-d203-2b2d8c971156"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","gtp-4o 응답 :  더불어민주당은 한동훈 국민의힘 대표가 윤석열 대통령 탄핵에 사실상 찬성하는 입장을 시사하자, 탄핵소추안 표결 시점을 앞당기는 방안을 검토 중입니다. 이재명 민주당 대표는 한 대표의 입장을 정확히 파악하는 것이 우선이라며 신중한 태도를 보였습니다. 민주당은 한 대표의 발언 이후 긴급 의원총회를 열어 당내 의견을 수렴하고 있으며, 표결 시점을 당초 예정된 7일 오후 7시에서 오후 5시로 앞당기는 방안을 논의하고 있습니다. 이는 국민의힘의 지연 전략을 고려한 조치입니다. 민주당은 현재 한 대표의 입장을 명확히 파악하는 것이 중요하다고 강조하며, 필요시 본회의 일정을 조정할 수 있다고 밝혔습니다.\n","gtp-4o 토큰수 :  194\n","\n","gtp-4.1 응답 :  ### 기사 핵심 요약\n","\n","**1. 민주당, 윤석열 대통령 탄핵소추안 표결 시점 앞당길지 고심**\n","- 한동훈 국민의힘 대표가 윤 대통령 탄핵에 사실상 찬성하는 듯한 발언을 하자, 민주당이 7일로 예정된 탄핵소추안 표결을 앞당기는 방안을 논의 중.\n","- 이재명 민주당 대표는 “한 대표의 입장을 정확히 파악하는 것이 우선”이라며 신중한 태도.\n","\n","**2. 긴장 고조 및 비상 대응**\n","- 민주당은 한동훈 대표의 입장 변화 이후 긴급 의원총회를 소집, 당내 의견 수렴.\n","- 민주당은 최근 정치인 체포 시도 등으로 긴장감이 높아졌으며, ‘2차 계엄’ 등 돌발 상황 가능성도 우려.\n","\n","**3. 표결 시점 조정 가능성**\n","- 민주당은 본회의 일정 변경을 공식 요청하진 않았으나, 필요시 표결을 앞당기는 방안도 검토 중.\n","- 구체적으로 7일 오후 7시에서 오후 5시로 앞당기는 방안이 거론됨. 국민의힘의 지연 전략에 대비하기 위한 조치.\n","\n","**4. 결론**\n","- 민주당은 한동훈 대표의 입장과 국민의힘의 대응을 예의주시하며, 탄핵소추안 표결 시점 조정 등 신속하고 신중한 대응 방안을 모색 중임.\n","gtp-4.1 토큰수 :  546\n"]}]},{"cell_type":"code","source":["# 모델별 가격(2025년 6월 기준, 1M=1,000,000 토큰)\n","PRICING = {\n","    \"gpt-4.1\": {\n","        \"input\": 2.00,    # $2.00 / 1M input tokens\n","        \"output\": 8.00    # $8.00 / 1M output tokens\n","    },\n","    \"gpt-4.1-mini\": {\n","        \"input\": 0.40,    # $0.40 / 1M input tokens\n","        \"output\": 1.60    # $1.60 / 1M output tokens\n","    },\n","    \"gpt-4.1-nano\": {\n","        \"input\": 0.10,    # $0.10 / 1M input tokens\n","        \"output\": 0.40    # $0.40 / 1M output tokens\n","    },\n","    \"o1\": {\n","        \"input\": 2.00,    # $2.00 / 1M input tokens\n","        \"output\": 8.00    # $8.00 / 1M output tokens\n","    },\n","    \"o3\": {\n","        \"input\": 2.00,    # $2.00 / 1M input tokens\n","        \"output\": 8.00    # $8.00 / 1M output tokens\n","    },\n","    \"o4-mini\": {\n","        \"input\": 1.10,    # $1.10 / 1M input tokens\n","        \"output\": 4.40    # $4.40 / 1M output tokens\n","    },\n","    \"gpt-4o\": {\n","        \"input\": 2.50,    # $2.50 / 1M input tokens\n","        \"output\": 10.00   # $10.00 / 1M output tokens\n","    },\n","    \"gpt-4o-mini\": {\n","        \"input\": 0.15,    # $0.15 / 1M input tokens\n","        \"output\": 0.60    # $0.60 / 1M output tokens\n","    }\n","}"],"metadata":{"id":"MNuVXHl0aGD4","executionInfo":{"status":"ok","timestamp":1750832956848,"user_tz":-540,"elapsed":40,"user":{"displayName":"Ryung","userId":"15350907190558487803"}}},"execution_count":59,"outputs":[]},{"cell_type":"code","source":["def count_tokens(text, model):\n","    if model == 'gpt-4.1':\n","        encoding = tiktoken.get_encoding('cl100k_base')\n","    else:\n","        encoding = tiktoken.encoding_for_model(model)\n","    encoded = encoding.encode(text)\n","    return len(encoded)\n","\n","def calc_cost(input_text, output_text, model, num_service_call=1_000_000):\n","    input_tokens = count_tokens(input_text, model)\n","    output_tokens = count_tokens(output_text, model)\n","\n","    # 모델별 단가 가져오기\n","    price = PRICING[model]\n","\n","    # 비용계산\n","    input_cost = (input_tokens / 1_000_000) * price['input']\n","    output_cost = (output_tokens / 1_000_000) * price['output']\n","\n","    total_cost = (input_cost + output_cost) * num_service_call\n","    return total_cost\n","\n","print('$', calc_cost(text, output_gpt4o, model='gpt-4o-mini'))\n","print('$', calc_cost(text, output_gpt41, model='gpt-4.1'))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oVs6h9ZPaXvG","executionInfo":{"status":"ok","timestamp":1750832958990,"user_tz":-540,"elapsed":23,"user":{"displayName":"Ryung","userId":"15350907190558487803"}},"outputId":"8cac9811-8561-4cd1-a65f-1cc70eeb563f"},"execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["$ 221.85\n","$ 6798.0\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"uweqaEVpaKJ3"},"execution_count":null,"outputs":[]}]}