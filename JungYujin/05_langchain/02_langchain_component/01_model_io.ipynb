{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMM6A8ZJR+9MwE/cDLU3Fhp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Model IO\n","<img src=\"https://d.pr/i/Wy5B5B+\" width=\"500\"/>\n","\n","- Language Model\n","- Prompt\n","- OutputParser\n"],"metadata":{"id":"ERoWhqLMfnUM"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rsuIcZY7fhNl","executionInfo":{"status":"ok","timestamp":1750996130823,"user_tz":-540,"elapsed":15316,"user":{"displayName":"Yujin Jung","userId":"00530649562276588864"}},"outputId":"5c884468-5f22-455e-9f48-3202f26157fa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.26)\n","Collecting langchain-openai\n","  Downloading langchain_openai-0.3.26-py3-none-any.whl.metadata (2.3 kB)\n","Collecting langchain-community\n","  Downloading langchain_community-0.3.26-py3-none-any.whl.metadata (2.9 kB)\n","Collecting langchain-huggingface\n","  Downloading langchain_huggingface-0.3.0-py3-none-any.whl.metadata (996 bytes)\n","Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.66)\n","Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n","Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.1)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n","Requirement already satisfied: openai<2.0.0,>=1.86.0 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.91.0)\n","Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n","Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (8.5.0)\n","Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n","  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n","Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n","  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n","Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n","  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n","Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n","Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.21.1)\n","Requirement already satisfied: huggingface-hub>=0.30.2 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.33.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.5.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n","  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n","Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (3.18.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (2025.3.2)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (24.2)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (4.67.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (4.14.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (1.1.5)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.10.18)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n","Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.9.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.9.0)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.10.0)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.3.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n","Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n","  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.6.15)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n","  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n","Downloading langchain_openai-0.3.26-py3-none-any.whl (70 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_community-0.3.26-py3-none-any.whl (2.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_huggingface-0.3.0-py3-none-any.whl (27 kB)\n","Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n","Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n","Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n","Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n","Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-openai, langchain-huggingface, langchain-community\n","Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.1 langchain-community-0.3.26 langchain-huggingface-0.3.0 langchain-openai-0.3.26 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.10.1 python-dotenv-1.1.1 typing-inspect-0.9.0\n"]}],"source":["!pip install langchain langchain-openai langchain-community langchain-huggingface"]},{"cell_type":"code","source":["# langsmith 환경설정\n","# colab secret 에 모두 등록할 것\n","from google.colab import userdata\n","import os\n","'''\n","LANGSMITH_TRACING=true\n","LANGSMITH_ENDPOINT=\"https://api.smith.langchain.com\"\n","LANGSMITH_API_KEY=\"<your-api-key>\"\n","LANGSMITH_PROJECT=\"skn14-langchain\"\n","OPENAI_API_KEY=\"<your-openai-api-key>\"\n","'''\n","os.environ['LANGSMITH_TRACING'] = userdata.get('LANGSMITH_TRACING')\n","os.environ['LANGSMITH_ENDPOINT'] = userdata.get('LANGSMITH_ENDPOINT')\n","os.environ['LANGSMITH_API_KEY'] = userdata.get('LANGSMITH_API_KEY')\n","os.environ['LANGSMITH_PROJECT'] = userdata.get('LANGSMITH_PROJECT')\n","os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n","\n","# secret 칸에 5개 적기"],"metadata":{"id":"CjmFP2rqgCLC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Language Models\n","\n","https://python.langchain.com/api_reference/reference.html#integrations\n","\n","LangChain의 Integrations 섹션에서는 다양한 다운스트림 LLM 모델과의 연동을 지원하다.\n","\n","이 섹션에서는 OpenAI, Hugging Face, GPT-4 등의 다양한 LLM 모델과 LangChain을 연결하는 방법을 다룬다."],"metadata":{"id":"nGj6q5GogUtc"}},{"cell_type":"code","source":["from langchain_openai import ChatOpenAI\n","\n","#llm=ChatOpenAI(model_name='gpt-4o')\n","llm.invoke('태국의 수도는 어디인가요?')\n"],"metadata":{"id":"LkTee7tlgClv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### huggingface"],"metadata":{"id":"4Gk9TQoPyO6J"}},{"cell_type":"code","source":["from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n","\n","llm = HuggingFaceEndpoint(repo_id='microsoft/Phi-3-mini-4k-instruct',\n","                          task ='text-generation')\n","\n","chat_model= ChatHuggingFace(\n","    llm=llm,\n","    verbose=True\n",")\n","\n","chat_model.invoke('Where is the capital of France?')\n"],"metadata":{"id":"GyISnGHYyOVt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_huggingface import HuggingFacePipeline\n","\n","pipe = HuggingFacePipeline.from_model_id (\n","    repo_id='microsoft/Phi-3-mini-4k-instruct',\n","    task='text-generation'\n",")\n","pipe.invoke('What is LLM?')\n"],"metadata":{"id":"D5MguJT4zTxu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# https://python.langchain.com/api_reference/anthropic/llms.html"],"metadata":{"id":"9uqeHhtr03h8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_anthropic import ChatAnthropic\n","from langchain_core.messages import HumanMessage\n","\n","# 모델 초기화\n","model = ChatAnthropic(\n","    model=\"claude-3-opus-20240229\",  # 또는 claude-3-sonnet, claude-3-haiku 등\n","    temperature=0,\n","    max_tokens=1024,\n","    api_key=ANTHROPIC_API_KEY,\n",")\n","\n","# 메시지 구성\n","message = HumanMessage(content=\"프랑스의 수도는 어디인가요?\")\n","\n","# 응답 생성\n","response = model.invoke([message])\n","print(response.content)"],"metadata":{"id":"MGZUZhek2kxx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Model Laboratory\n","- 여러 LLM을 동시에 비교할 수 있는\n","실험도구"],"metadata":{"id":"lqgFgcX01Xt2"}},{"cell_type":"code","source":["from langchain.model_laboratory import ModelLaboratory\n","\n","llms=[\n","    ChatOpenAI(model_name='gpt-3.5-turbo'),\n","    ChatOpenAI(model_name='gpt-4.1'),\n","]\n","\n","lab=ModelLaboratory.from_llms(llms)\n","lab.compare('파이썬의 장점이 무엇인가요?')\n","\n"],"metadata":{"id":"2IHROL-r1f9k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Prompts\n"],"metadata":{"id":"8w4FR-ke06Ad"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["https://python.langchain.com/api_reference/core/prompts.html#langchain-core-prompts\n","\n","`LangChain`의 API 문서에서 제공하는 **Prompts**에 대한 내용은 LangChain 프레임워크의 **핵심 구성 요소 중 하나**로, LLM(Large Language Model)과의 인터페이스를 설정하는 데 중요한 역할을 한다. Prompts는 LLM에 전달될 입력을 정의하고, 구조화하며, 이를 기반으로 원하는 응답을 얻기 위해 사용된다.\n","\n","**주요 사용처**\n","\n","1. **자동화된 입력 구성**\n","   - PromptTemplate을 사용하여 사용자 입력을 자동으로 구성.\n","   - 동일한 형식의 질문이나 대화를 대량으로 생성 가능.\n","\n","2. **대화형 응답**\n","   - ChatPromptTemplate을 통해 대화형 AI의 문맥 유지를 지원.\n","\n","3. **샘플 기반 학습**\n","   - Few-shot Prompt는 LLM에 구체적인 예제를 제공해 정확한 응답을 유도.\n","\n","4. **결과 파싱**\n","   - Output Parsers를 통해 LLM의 출력을 특정 포맷으로 처리하여 후속 작업을 자동화.\n","\n","\n","**클래스 계층구조**\n","```\n","BasePromptTemplate\n","├─ PipelinePromptTemplate\n","├─ StringPromptTemplate\n","│  ├─ PromptTemplate\n","│  ├─ FewShotPromptTemplate\n","│  └─ FewShotPromptWithTemplates\n","└─ BaseChatPromptTemplate\n","   ├─ AutoGPTPrompt\n","   └─ ChatPromptTemplate\n","      └─ AgentScratchPadChatPromptTemplate\n","\n","BaseMessagePromptTemplate\n","├─ MessagesPlaceholder\n","└─ BaseStringMessagePromptTemplate\n","   ├─ ChatMessagePromptTemplate\n","   ├─ HumanMessagePromptTemplate\n","   ├─ AIMessagePromptTemplate\n","   └─ SystemMessagePromptTemplate\n","\n","```"],"metadata":{"id":"V3rbiT_k2vMx"}},{"cell_type":"code","source":["from langchain_openai import ChatOpenAI\n","\n","llm=ChatOpenAI(model_name='gpt-4o-mini')\n","# 환경변수 설정에 os.environ 으로 적혀있어서 api_key 입력 생략\n","\n","llm.invoke('LLM이 뭔가요?')"],"metadata":{"id":"RbW-TiVt2d9F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["messages = [\n","    ('system','당신은 친절한 초딩전용 챗봇입니다. 초딩의 눈높이에 맞게 설명해주세요.'),\n","    ('human', '랭체인이 뭔가요?')\n","\n","]\n","llm.invoke(messages)\n","\n"],"metadata":{"id":"gXNGbzHx3pQk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### PromptTemplate"],"metadata":{"id":"jlIMbJLw4O-s"}},{"cell_type":"code","source":["from langchain import PromptTemplate\n","\n","# 어떤 상품에 대한 광고문구를 생성\n","prompt_template = PromptTemplate(\n","    template='{product}를 홍보하기 위한 신박한 광고문구를 작성해줘',\n","    input_variables=[\"product\"]\n",")\n","prompt = prompt_template.format(product='초소형 카메라')\n","prompt = prompt_template.format(product='냉장고')\n","\n","ai_message = llm.invoke(prompt)\n","print(ai_message.content)\n","\n","\n"],"metadata":{"id":"kcErISCu4RDe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### ChatPromptTemplate"],"metadata":{"id":"chkZb6fg5sMm"}},{"cell_type":"code","source":["from langchain.prompts.chat import (ChatPromptTemplate,\n","                                    SystemMessagePromptTemplate,\n","                                    HumanMessagePromptTemplate,\n",")\n","\n","system_msg_template = SystemMessagePromptTemplate.from_template(\"당신은 {domain}분야의 최고의 챗봇입니다.\")\n","human_msg_template = HumanMessagePromptTemplate.from_template(\"{question}\")\n","\n","chat_template = ChatPromptTemplate.from_messages([\n","    system_msg_template, human_msg_template])\n","\n","prompt = chat_template.format_messages(domain='IT', question='LLM이 뭐야?')\n","prompt\n","\n","llm.invoke(prompt).content\n"],"metadata":{"id":"KrCzqcEr5vAk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt = chat_template.format_messages(domain='육아', question='애들이 밥을 잘 안먹는 이유?')\n","prompt\n","\n","print(llm.invoke(prompt).content)"],"metadata":{"id":"hBiuEVSC7UF-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### FewShotPromptTemplate"],"metadata":{"id":"oJcdJ0usCiVw"}},{"cell_type":"code","source":["from langchain.prompts import FewShotPromptTemplate\n","\n","example = [\n","    {'q': '2+2=?', 'a': '4'},\n","    {'q': '3+5=?', 'a': '8'},\n","]\n","\n","prompt_template = PromptTemplate(\n","    template = 'Q: {q}\\nA: {a}',\n","    input_variables=['q','a']\n",")\n","\n","fewshot_template = FewShotPromptTemplate(\n","    examples=examples,\n","    example_prompt=prompt_template,\n","    prefix='다음 수학문제를 풀어주세요(답변은 정답만 출력하세요):',\n","    suffix='Q: {question}\\nA:', #사용자입력값\n","    input_variables=['question']\n",")\n","prompt = fewshot_template.format(queston='123+345=?')\n","print(prompt)"],"metadata":{"id":"w7KyoVTCCk77"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(llm.invoke(prompt).content)"],"metadata":{"id":"BgP0PdGaEIRY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Output Parsers\n","\n","https://python.langchain.com/api_reference/langchain/output_parsers.html#module-langchain.output_parsers\n","\n","LangChain의 Output Parsers는 LLM이 생성한 텍스트 출력을 특정 형식으로 변환하거나 처리하는 데 사용된다. 이는 모델의 응답을 해석하고, 이를 구조화된 데이터로 바꿔 후속 작업에 활용하기 위해 설계되었다. Output Parsers는 LangChain의 응답 처리 워크플로우에서 중요한 역할을 한다.\n","\n","예를 들어, LLM 응답이 \"Name: John, Age: 30\"와 같은 텍스트라면, 이를 {\"name\": \"John\", \"age\": 30}과 같은 Python 딕셔너리로 변환 가능.\n","\n","**사용 목적**\n","- 모델의 출력을 특정 애플리케이션에 맞게 처리해야 하는 경우가 많음.\n","- 응답을 해석하는 일관성과 정확성을 높이기 위해 필요.\n","- 텍스트 기반 응답을 JSON, 리스트 또는 숫자와 같은 특정 포맷으로 변환하여 후속 작업에 활용.\n","\n","**종류**\n","1. **BaseOutputParser**: Output Parsers의 기본 클래스, 커스텀 파서 구현 시 사용.  \n","2. **CommaSeparatedListOutputParser**: 콤마로 구분된 문자열을 리스트로 변환.  \n","3. **RegexParser**: 정규식을 사용해 특정 패턴을 추출하고 키-값 형태로 반환.  \n","4. **StructuredOutputParser**: 출력의 JSON 또는 구조화된 형식을 강제.  \n","5. **PydanticOutputParser**: Pydantic 모델을 기반으로 출력 검증 및 변환.  \n","6. **MarkdownOutputParser**: 마크다운 형식의 텍스트에서 데이터를 추출.  "],"metadata":{"id":"LHdZDjxdEsuh"}},{"cell_type":"code","source":["### CommaSeperatedListOutputParser"],"metadata":{"id":"sM90GqlMEhHU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain.output_parsers import CommaSeparatedListOutputParser\n","model_output = \"사과, 바나나, 오렌지, 포도\"\n","output_parser = CommaSeparatedListOutputParser()\n","output = output_parser.parse(model_output)\n","output\n"],"metadata":{"id":"wninMjZOEhZP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 야구팀 5개 질문\n","# 축구팀 10개 질문\n","\n","prompt_template = PromptTemplate(\n","    template=\"{subject}{n}개의 팀을 보여주세요.\\n{format_instruction}\",\n","    input_variables=['subject','n'], # 사용자 프롬프트로 채워질 변수\n","    partial_variables={\n","        # template 생성시에 채워짐\n","        'format_instruction': output_parser.get_format_instructions()\n","    }\n",")\n","prompt = prompt_template.format(subject='대한민국 프로야구',n=5)\n","prompt = prompt_template.format(subject='프리미어리그',n=5)\n","prompt"],"metadata":{"id":"0dw4v3T8Ehp_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ai_message = llm.invoke(prompt)\n","output = ai_message.content\n","# 출력파서가 가공한 최종출력\n","output = output_parser.parse(output)\n","output\n","# 맨유, 리버풀, 아스널, 첼시, 맨체스터 시티"],"metadata":{"id":"4s-L1xHtHesr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["chain= prompt_template | llm | output_parser\n","chain.invoke(input={'subject':'프로농구','n':3})"],"metadata":{"id":"lcE_XDM5IWdl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### JSONOutputParser"],"metadata":{"id":"AFOzMTCVJEyo"}},{"cell_type":"code","source":["from langchain_core.output_parsers import JsonOutputParser\n","model_output = '{\"title\":\"GPT-5를 소개합니다.\",\"author\":\"OpenAI\",\"pages\":250}'\n","#문자열은 모두 쌍따옴표, 숫자는 그대로 쓴다.\n","json_parser = JsonOutputParser()\n","print(json_parser.get_format_instructions())\n","\n","output = json_parser.parse(model_output) # json_str -> python object (list, dict)\n","print(output)\n","print(type(output))\n"],"metadata":{"id":"QvFWnm0eJDl2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 연습문제"],"metadata":{"id":"T8RS-KoDRQA0"}},{"cell_type":"code","source":["# {AI} 관련 책 {3}권을 보여주세요.(json)\n","# {요리} 관련 책 {5}권을 보여주세요.(json)\n","# PromptTemplate - LLM - JsonOutputParser\n"],"metadata":{"id":"0nRMH2VENHk9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["json_parser = JsonOutputParser()\n","\n","prompt_template = PromptTemplate(\n","    template=\"{subject} 관련 한국어 책 {n}권을 보여주세요.(실제 있는 책만 작성하고 절대 지어내지 마세요.)\\n{format_instruction}\",\n","    input_variables=['subject','n'], # 사용자 프롬프트로 채워질 변수\n","    partial_variables={\n","        # template 생성시에 채워짐\n","        'format_instruction': output_parser.get_format_instructions()\n","    }\n",")\n","#prompt = prompt_template.format(subject='요리',n=5)\n","\n","llm= ChatOpenAI(model_name='gpt-4o-mini')\n","\n","prompt = prompt_template.format(subject='AI',n=3)\n","\n","ai_message = llm.invoke(prompt)\n","output = json_parser.parse(ai_message.content)\n","print(output)\n","\n","chain= prompt_template | llm | json_parser\n","output = chain.invoke(input={'subject':'AI','n':3})\n","print(output)\n","\n","# 없는 책 지어내는 경우도 있으므로 주의!\n","\n"],"metadata":{"id":"xG1V_ZqsORhm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_core.output_parsers import JsonOutputParser\n","model_output = '{\"title\":\"GPT-5를 소개합니다.\",\"author\":\"OpenAI\",\"pages\":250}'\n","#문자열은 모두 쌍따옴표, 숫자는 그대로 쓴다.\n","json_parser = JsonOutputParser()\n","print(json_parser.get_format_instructions())\n","\n","output = json_parser.parse(model_output) # json_str -> python object (list, dict)\n","print(output)\n","print(type(output))\n"],"metadata":{"id":"U_wF2TMBNkcH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"bO0stbjwNkpP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3N9-8bE0Nk7a"},"execution_count":null,"outputs":[]}]}