{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN5HfLkKfYeuCrf2N+xBLrc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# STT Speech to Text"],"metadata":{"id":"HaI4e14f1TIw"}},{"cell_type":"markdown","source":["## Whisper\n","\n","https://platform.openai.com/docs/models#whisper\n","\n","https://openai.com/index/whisper/\n","\n","Whisper는 OpenAI에서 개발한 범용 음성 인식 모델로, 다양한 오디오 데이터셋을 학습하여 다국어 음성 인식, 음성 번역, 언어 식별 등의 작업을 수행할 수 있다.\n","\n","Whisper v2-large 모델은 현재 API를 통해 'whisper-1'이라는 이름으로 제공되고 있다.\n","\n","오픈 소스 버전의 Whisper와 API를 통한 Whisper는 기능적으로 동일하지만, API를 통해 제공되는 버전은 최적화된 추론 과정을 거쳐 다른 방법에 비해 더 빠르게 동작한다.\n","\n","\n","![Whisper 모델 아키텍처](https://images.ctfassets.net/kftzwdyauwt9/d9c13138-366f-49d3-a1a563abddc1/8acfb590df46923b021026207ff1a438/asr-summary-of-model-architecture-desktop.svg?w=1920&q=90)\n"],"metadata":{"id":"f2t74YVb1fUJ"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"ca62YXlX1RF2","executionInfo":{"status":"ok","timestamp":1750835186286,"user_tz":-540,"elapsed":2884,"user":{"displayName":"Ryung","userId":"15350907190558487803"}}},"outputs":[],"source":["from google.colab import userdata\n","\n","OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')"]},{"cell_type":"code","source":["!gdown 1zHD6wDwqGyDzAp9Y254SZEruRALiK9Rw"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B0x7Mkv36KS_","executionInfo":{"status":"ok","timestamp":1750835189751,"user_tz":-540,"elapsed":3459,"user":{"displayName":"Ryung","userId":"15350907190558487803"}},"outputId":"4633a695-b13a-4c50-e8dc-397bc9daac49"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1zHD6wDwqGyDzAp9Y254SZEruRALiK9Rw\n","To: /content/output.mp3\n","\r  0% 0.00/52.8k [00:00<?, ?B/s]\r100% 52.8k/52.8k [00:00<00:00, 101MB/s]\n"]}]},{"cell_type":"code","source":["from openai import OpenAI\n","\n","client = OpenAI(api_key=OPENAI_API_KEY)\n","\n","file_path = 'output.mp3'\n","\n","with open (file_path, 'rb') as f:\n","  transcription = client.audio.transcriptions.create(\n","      model='whisper-1',\n","      file=f\n","  )\n","  print(transcription)\n","  print(transcription.text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"exs-utzH6LPU","executionInfo":{"status":"ok","timestamp":1750835320045,"user_tz":-540,"elapsed":1584,"user":{"displayName":"Ryung","userId":"15350907190558487803"}},"outputId":"fca89456-4bd9-4e37-d3af-9c42c889ef7a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Transcription(text='오늘은 날씨가 맑고 매우 좋습니다.', logprobs=None, usage={'type': 'duration', 'seconds': 3})\n","오늘은 날씨가 맑고 매우 좋습니다.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"DzHv9F0Q6rzj"},"execution_count":null,"outputs":[]}]}