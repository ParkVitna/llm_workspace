{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOMmNXqfoQYmFfof43l6iq3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Model IO\n","<img src=\"https://d.pr/i/Wy5B5B+\" width=\"500\"/>\n","\n","- Language Model\n","- Prompt\n","- OutputParser"],"metadata":{"id":"l6KAmTlUgDoA"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tYUmfaYzfiUP","executionInfo":{"status":"ok","timestamp":1751001904240,"user_tz":-540,"elapsed":7188,"user":{"displayName":"강윤구","userId":"06321173146398152973"}},"outputId":"ebc48dff-01ba-4376-bfdd-d06513b5df29"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.26)\n","Requirement already satisfied: langchain-openai in /usr/local/lib/python3.11/dist-packages (0.3.26)\n","Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.26)\n","Requirement already satisfied: langchain-huggingface in /usr/local/lib/python3.11/dist-packages (0.3.0)\n","Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.66)\n","Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n","Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.1)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n","Requirement already satisfied: openai<2.0.0,>=1.86.0 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.91.0)\n","Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n","Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (8.5.0)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n","Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.10.1)\n","Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.1)\n","Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n","Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.21.1)\n","Requirement already satisfied: huggingface-hub>=0.30.2 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.33.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.5.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (3.18.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (2025.3.2)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (24.2)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (4.67.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (4.14.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (1.1.5)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.10.18)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n","Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.9.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.9.0)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.10.0)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.3.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n","Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.6.15)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n"]}],"source":["!pip install langchain langchain-openai langchain-community langchain-huggingface"]},{"cell_type":"code","source":["from google.colab import userdata\n","import os\n","\n","os.environ[\"LANGSMITH_TRACING\"] = userdata.get('LANGSMITH_TRACING')\n","os.environ[\"LANGSMITH_ENDPOINT\"] = userdata.get('LANGSMITH_ENDPOINT')\n","os.environ[\"LANGSMITH_API_KEY\"] = userdata.get('LANGSMITH_API_KEY')\n","os.environ[\"LANGSMITH_PROJECT\"] = userdata.get('LANGSMITH_PROJECT')\n","os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"],"metadata":{"id":"rek3aSbsgKf4","executionInfo":{"status":"ok","timestamp":1751001906332,"user_tz":-540,"elapsed":2087,"user":{"displayName":"강윤구","userId":"06321173146398152973"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## Language Models\n","\n","https://python.langchain.com/api_reference/reference.html#integrations\n","\n","LangChain의 Integrations 섹션에서는 다양한 다운스트림 LLM 모델과의 연동을 지원하다.\n","\n","이 섹션에서는 OpenAI, Hugging Face, GPT-4 등의 다양한 LLM 모델과 LangChain을 연결하는 방법을 다룬다."],"metadata":{"id":"c0L3uLJSwmyH"}},{"cell_type":"markdown","source":["## openai"],"metadata":{"id":"hxvsr6prxQag"}},{"cell_type":"code","source":["from langchain_openai import ChatOpenAI\n","\n","llm = ChatOpenAI(model_name='gpt-4o')\n","\n","llm.invoke('태국의 수도는 어디인가요?')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m6EoTML9wno0","executionInfo":{"status":"ok","timestamp":1751001909685,"user_tz":-540,"elapsed":3348,"user":{"displayName":"강윤구","userId":"06321173146398152973"}},"outputId":"411a7f9e-16e0-4ac8-fe74-ca9da695f34b"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AIMessage(content='태국의 수도는 방콕입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 16, 'total_tokens': 26, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'id': 'chatcmpl-BmvsD24F3G87KOllbEZ5jt1LBD6q6', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--03e7abb8-5c89-4bcf-8f6b-2fc2f7b03835-0', usage_metadata={'input_tokens': 16, 'output_tokens': 10, 'total_tokens': 26, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["## huggingface"],"metadata":{"id":"-O6nvH7GyUq1"}},{"cell_type":"code","source":["from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n","\n","llm = HuggingFaceEndpoint(\n","    repo_id='microsoft/Phi-3-mini-4k-instruct',\n","    task='text-generation'\n",")\n","\n","chat_model = ChatHuggingFace(\n","    llm=llm,\n","    verbose=True\n",")\n","\n","chat_model.invoke('프랑스의 수도는 어디인가요?')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_K35WsogyV1y","executionInfo":{"status":"ok","timestamp":1751001918165,"user_tz":-540,"elapsed":8478,"user":{"displayName":"강윤구","userId":"06321173146398152973"}},"outputId":"365278e6-22dd-44ff-bb89-7829e781f0d1"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AIMessage(content='프랑스의 수도는 삼성전자주행항공장, 인천을 주지요. 귀사의 중점 지도는 다음과 같습니다.\\n\\n- 인천 국토주간간선\\n- 특별 제로 기구\\n- 혼합 지도으로 관광객을 수서으로 인생의 중요 지도로 의존\\n\\n또한, 수도는 인천 국토영향센터와 관련된 장소에 위치하고 있습니다.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 214, 'prompt_tokens': 25, 'total_tokens': 239}, 'model_name': 'microsoft/Phi-3-mini-4k-instruct', 'system_fingerprint': '3.2.1-sha-4d28897', 'finish_reason': 'stop', 'logprobs': None}, id='run--55cb2485-8553-439f-9329-9c3f9fe1c279-0', usage_metadata={'input_tokens': 25, 'output_tokens': 214, 'total_tokens': 239})"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["# from langchain_huggingface import HuggingFacePipeline\n","\n","# pipe = HuggingFacePipeline.from_model_id(\n","#     model_id='microsoft/Phi-3-mini-4k-instruct',\n","#     task='text-generation'\n","# )\n","# pipe.invoke('what is LLM?')"],"metadata":{"id":"DnyNOKkHziZm","executionInfo":{"status":"ok","timestamp":1751001918172,"user_tz":-540,"elapsed":3,"user":{"displayName":"강윤구","userId":"06321173146398152973"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["### ModelLaboratory\n","- 여러LLM을 동시에 비교할 수 있는 실험도구"],"metadata":{"id":"1NYCm7DD1onG"}},{"cell_type":"code","source":["from langchain.model_laboratory import ModelLaboratory\n","\n","llms = [\n","    ChatOpenAI(model_name='gpt-3.5-turbo'),\n","    ChatOpenAI(model_name='gpt-4.1'),\n","]\n","\n","lab = ModelLaboratory.from_llms(llms)\n","lab.compare('파이썬의 장점이 무엇인가요?')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jWB-pZVV1pyX","executionInfo":{"status":"ok","timestamp":1751001966957,"user_tz":-540,"elapsed":11528,"user":{"displayName":"강윤구","userId":"06321173146398152973"}},"outputId":"809c6747-a2f9-487b-bcb7-ba8dd776f200"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1mInput:\u001b[0m\n","파이썬의 장점이 무엇인가요?\n","\n","client=<openai.resources.chat.completions.completions.Completions object at 0x7b449cf95890> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7b449cf95f90> root_client=<openai.OpenAI object at 0x7b44a5e2c990> root_async_client=<openai.AsyncOpenAI object at 0x7b44a410ea50> model_kwargs={} openai_api_key=SecretStr('**********')\n","\u001b[36;1m\u001b[1;3m1. 쉬운 학습 곡선: 파이썬은 다른 프로그래밍 언어에 비해 문법이 간단하고 직관적이어서 초보자도 쉽게 학습할 수 있습니다.\n","\n","2. 다양한 라이브러리와 모듈: 파이썬에는 다양한 라이브러리와 모듈이 내장되어 있어서 다양한 작업을 간편하게 수행할 수 있습니다.\n","\n","3. 대중적인 프로그래밍 언어: 파이썬은 전 세계적으로 가장 인기 있는 프로그래밍 언어 중 하나이며, 커뮤니티와 도움자료가 풍부합니다.\n","\n","4. 크로스 플랫폼 지원: 파이썬은 윈도우, 맥, 리눅스 등 다양한 운영체제에서 모두 사용할 수 있습니다.\n","\n","5. 데이터 처리와 분석에 용이: 파이썬은 데이터 처리와 분석을 위한 라이브러리인 Pandas, NumPy, Scikit-learn 등을 제공하여 데이터 과학 및 인공지능 분야에서 널리 사용되고 있습니다.\u001b[0m\n","\n","client=<openai.resources.chat.completions.completions.Completions object at 0x7b449cf96510> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7b449cf96e90> root_client=<openai.OpenAI object at 0x7b449cf96190> root_async_client=<openai.AsyncOpenAI object at 0x7b449cf968d0> model_name='gpt-4.1' model_kwargs={} openai_api_key=SecretStr('**********')\n","\u001b[33;1m\u001b[1;3m파이썬(Python)의 장점은 다음과 같습니다:\n","\n","1. **간결하고 읽기 쉬운 문법**  \n","   - 다른 언어에 비해 문법이 간단하고 코드가 직관적입니다. 유지보수와 협업에 유리합니다.\n","\n","2. **다양한 라이브러리와 프레임워크**  \n","   - 데이터 분석(Numpy, Pandas), 인공지능(TensorFlow, PyTorch), 웹 개발(Django, Flask) 등 방대한 라이브러리가 지원됩니다.\n","\n","3. **플랫폼 독립성**  \n","   - 운영체제에 상관 없이 어디서나 동작합니다. (Windows, Mac, Linux 등)\n","\n","4. **큰 커뮤니티와 방대한 자료**  \n","   - 전 세계적으로 많은 개발자들이 사용하며, 질문과 답변, 예제 코드, 오픈소스 프로젝트가 풍부합니다.\n","\n","5. **생산성 향상**  \n","   - 빠른 프로토타입 개발이 가능해 아이디어를 신속하게 실제 프로그램으로 만들 수 있습니다.\n","\n","6. **동적 타이핑**  \n","   - 변수 선언 시 타입을 지정하지 않아도 자동으로 처리됩니다.\n","\n","7. **학습 용이성**  \n","   - 초보자부터 전문가까지 배우기 쉽고, 교육용으로도 널리 사용됩니다.\n","\n","8. **확장성**  \n","   - 다른 언어(C, C++, Java 등)와도 쉽게 연동할 수 있습니다.\n","\n","요약하면 파이썬은 쉽고, 강력하며, 활용 범위가 넓어서 프로그래밍을 시작하려는 사람이나 다양한 분야의 개발자 모두에게 인기 있는 언어입니다.\u001b[0m\n","\n"]}]},{"cell_type":"markdown","source":["## Prompts\n","https://python.langchain.com/api_reference/core/prompts.html#langchain-core-prompts\n","\n","`LangChain`의 API 문서에서 제공하는 **Prompts**에 대한 내용은 LangChain 프레임워크의 **핵심 구성 요소 중 하나**로, LLM(Large Language Model)과의 인터페이스를 설정하는 데 중요한 역할을 한다. Prompts는 LLM에 전달될 입력을 정의하고, 구조화하며, 이를 기반으로 원하는 응답을 얻기 위해 사용된다.\n","\n","**주요 사용처**\n","\n","1. **자동화된 입력 구성**\n","   - PromptTemplate을 사용하여 사용자 입력을 자동으로 구성.\n","   - 동일한 형식의 질문이나 대화를 대량으로 생성 가능.\n","\n","2. **대화형 응답**\n","   - ChatPromptTemplate을 통해 대화형 AI의 문맥 유지를 지원.\n","\n","3. **샘플 기반 학습**\n","   - Few-shot Prompt는 LLM에 구체적인 예제를 제공해 정확한 응답을 유도.\n","\n","4. **결과 파싱**\n","   - Output Parsers를 통해 LLM의 출력을 특정 포맷으로 처리하여 후속 작업을 자동화.\n","\n","\n","**클래스 계층구조**\n","```\n","BasePromptTemplate\n","├─ PipelinePromptTemplate\n","├─ StringPromptTemplate\n","│  ├─ PromptTemplate\n","│  ├─ FewShotPromptTemplate\n","│  └─ FewShotPromptWithTemplates\n","└─ BaseChatPromptTemplate\n","   ├─ AutoGPTPrompt\n","   └─ ChatPromptTemplate\n","      └─ AgentScratchPadChatPromptTemplate\n","\n","BaseMessagePromptTemplate\n","├─ MessagesPlaceholder\n","└─ BaseStringMessagePromptTemplate\n","   ├─ ChatMessagePromptTemplate\n","   ├─ HumanMessagePromptTemplate\n","   ├─ AIMessagePromptTemplate\n","   └─ SystemMessagePromptTemplate\n","\n","```\n"],"metadata":{"id":"HuWXLC4a2bzU"}},{"cell_type":"code","source":["from langchain_openai import ChatOpenAI\n","\n","llm = ChatOpenAI(model_name='gpt-4o-mini')\n","\n","llm.invoke('LLM이 뭔가요?')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jaxY6pIc3e9V","executionInfo":{"status":"ok","timestamp":1751002301629,"user_tz":-540,"elapsed":4451,"user":{"displayName":"강윤구","userId":"06321173146398152973"}},"outputId":"f8fe559a-68a8-43a0-dfe4-9ce9a2614792"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AIMessage(content='LLM은 \"Large Language Model\"의 약자로, 대규모 언어 모델을 의미합니다. 이러한 모델은 자연어 처리(NLP) 작업을 수행하기 위해 개발되었으며, 대량의 텍스트 데이터를 학습하여 언어의 패턴과 구조를 이해합니다. LLM은 텍스트 생성, 질문 응답, 번역, 요약 등 다양한 언어 관련 작업을 수행하는 데 사용됩니다.\\n\\n대표적인 LLM의 예로는 OpenAI의 GPT-3, GPT-4, Google의 BERT, T5 등이 있습니다. 이러한 모델들은 인공지능 기술 발전에 큰 영향을 미치고 있으며, 많은 기업과 연구자들이 LLM을 활용하여 다양한 응용 프로그램을 개발하고 있습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 157, 'prompt_tokens': 15, 'total_tokens': 172, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BmvyUttVoum75nbjeBzhISo8DPOvg', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--2753ee76-bbfc-4879-8018-c53780a2f7f0-0', usage_metadata={'input_tokens': 15, 'output_tokens': 157, 'total_tokens': 172, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["messages = [\n","    ('system', '당신은 친절한 초딩전용 챗봇입니다. 초딩의 눈높이에 맞게 설명해주세요.'),\n","    ('human', '랭체인이 뭔가요?')\n","]\n","\n","llm.invoke(messages)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Bj1sdwI3rLm","executionInfo":{"status":"ok","timestamp":1751002443181,"user_tz":-540,"elapsed":4560,"user":{"displayName":"강윤구","userId":"06321173146398152973"}},"outputId":"a28fd155-fdab-449a-bca1-1c75c2a8ae76"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AIMessage(content='랭체인은 \"Language Chain\"의 줄임말로, 여러 가지 언어를 연결해주는 기술이나 기법이야. 주로 인공지능(AI)과 관련된 것인데, 언어를 서로 번역하거나 어떤 문장을 생성하는 데 도움을 줄 수 있어. 쉽게 말해서, 여러 언어를 사용할 수 있도록 도와주는 시스템이라고 생각하면 돼!\\n\\n예를 들어, 너가 한국어로 질문을 하면, AI가 그 질문을 영어로 바꿔서 답변할 수도 있고, 또 다른 언어로도 답변할 수 있는 거야. 이렇게 여러 언어를 연결하는 역할을 해주는 거지!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 142, 'prompt_tokens': 47, 'total_tokens': 189, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-Bmw0mmBQmlypOBeNVqI4nPr1TDldb', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--8bf7a3bb-f821-417d-bd02-6f09c21a57f5-0', usage_metadata={'input_tokens': 47, 'output_tokens': 142, 'total_tokens': 189, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["## PromptTemplate"],"metadata":{"id":"z85YrY_z4TDO"}},{"cell_type":"code","source":["from langchain import PromptTemplate\n","\n","# 어떤 상품에 대한 광고문구를 생성\n","\n","prompt_template = PromptTemplate(\n","    template='{product}를 홍보하기 위한 신박한 광고문구를 작성해줘',\n","    input_variables=[\"product\"]\n",")\n","prompt = prompt_template.format(product='초소형 카메라')\n","prompt = prompt_template.format(product='냉털전용 냉장고')\n","\n","ai_message = llm.invoke(prompt)\n","print(ai_message.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"94B8QtM84VB-","executionInfo":{"status":"ok","timestamp":1751004065551,"user_tz":-540,"elapsed":2523,"user":{"displayName":"강윤구","userId":"06321173146398152973"}},"outputId":"dfba8b51-3ed9-4818-95a2-7d69e5030c34"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["\"신선함을 지켜주는 냉털전용 냉장고! 🌟 당신의 소중한 재료를 언제 어디서나 막강한 냉기로 지킵니다. 냉장고에서 펼쳐지는 신선한 세계, 이제 냉털이 아닌 냉장고에서 경험하세요! #신선함의끝판왕 #냉털전문가\"\n"]}]},{"cell_type":"markdown","source":["### ChatPromptTemplate"],"metadata":{"id":"rdsViXDw-c9t"}},{"cell_type":"code","source":["from langchain.prompts.chat import (\n","    ChatPromptTemplate,\n","    SystemMessagePromptTemplate,\n","    HumanMessagePromptTemplate\n",")\n","\n","system_msg_template = SystemMessagePromptTemplate.from_template(\"당신은 {domain}분야의 최고의 챗봇입니다.\")\n","human_msg_template = HumanMessagePromptTemplate.from_template(\"{question}\")\n","chat_template = ChatPromptTemplate.from_messages([\n","    system_msg_template, human_msg_template\n","])\n","\n","prompt = chat_template.format_messages(domain='IT', question='LLM이 뭐야?')\n","print(llm.invoke(prompt).content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"49iIS4UN-eDW","executionInfo":{"status":"ok","timestamp":1751004090538,"user_tz":-540,"elapsed":4758,"user":{"displayName":"강윤구","userId":"06321173146398152973"}},"outputId":"65f0f251-29cf-47d9-f783-fa96a8d2e58b"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["LLM은 \"Large Language Model\"의 약자로, 대규모 언어 모델을 의미합니다. 이러한 모델은 대량의 텍스트 데이터를 학습하여 언어를 이해하고 생성하는 능력을 갖춘 인공지능 시스템입니다. 주로 자연어 처리(NLP) 분야에서 사용되며, 질문에 답하거나 텍스트를 요약, 번역, 생성하는 등의 작업을 수행할 수 있습니다.\n","\n","LLM의 예로는 OpenAI의 GPT(Generative Pre-trained Transformer) 시리즈, Google's BERT, T5 등이 있습니다. 이러한 모델들은 일반적으로 수십억 개의 매개변수를 가지고 있으며, 이를 통해 다양한 언어 관련 작업에서 높은 성능을 발휘할 수 있습니다.\n"]}]},{"cell_type":"code","source":["prompt = chat_template.format_messages(domain='육아', question='우리 애가 밥을 안먹어요. 어떻하면 좋을까요?')\n","print(llm.invoke(prompt).content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dWT4xT8V-fbN","executionInfo":{"status":"ok","timestamp":1751004097020,"user_tz":-540,"elapsed":6477,"user":{"displayName":"강윤구","userId":"06321173146398152973"}},"outputId":"8b36a0f8-3aa1-4200-9ced-21892439c73c"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["아이의 식사가 문제일 때는 여러 가지 접근 방법이 있습니다. 다음과 같은 방법을 시도해 보세요:\n","\n","1. **식사 환경 조성**: 편안하고 긍정적인 분위기를 만들어 주세요. TV나 스마트폰을 멀리하고 함께 앉아 이야기하며 식사하는 것이 좋습니다.\n","\n","2. **식사 시간 정하기**: 규칙적인 식사 시간을 설정하여 아이의 식습관을 형성해 주세요. 일정한 시간에 식사하면 배고픔을 느끼게 됩니다.\n","\n","3. **신선한 재료 사용**: 다양한 색깔과 모양의 채소나 과일을 사용하여 시각적으로도 매력적으로 만들어 주세요. 아이들이 좋아하는 음식이 있다면 그것을 사용해 보는 것도 좋습니다.\n","\n","4. **작은 양 제공**: 처음부터 많은 양을 주기보다는 작은 양으로 시작하고, 아이가 원할 경우 양을 늘려주세요.\n","\n","5. **가족이 함께 먹기**: 가족 모두가 같은 음식을 먹는 것이 좋습니다. 아이는 부모의 식습관을 보고 배우기 때문입니다.\n","\n","6. **요리 참여**: 아이에게 음식을 준비하게 하여 흥미를 유도하세요. 자신이 만든 음식을 더 먹고 싶어할 수 있습니다.\n","\n","7. **강요하지 않기**: 식사 때 강제로 먹이려고 하지 마세요. 아이가 스스로 먹고 싶어할 때까지 기다리는 것도 중요합니다.\n","\n","8. **의사와 상담**: 만약 지속적으로 식사가 불규칙하거나 체중 감소가 있다면 소아과 의사와 상담하는 것이 좋습니다.\n","\n","아이의 먹는 습관은 시간이 지남에 따라 변할 수 있습니다. 인내심을 가지고 다양한 방법을 시도해 보세요!\n"]}]},{"cell_type":"markdown","source":["### FewShotPromptTemplate"],"metadata":{"id":"0hu6bNojC5JX"}},{"cell_type":"code","source":["from langchain.prompts import FewShotPromptTemplate\n","\n","examples = [\n","    {'q': '2 + 2 = ?', 'a': '4'},\n","    {'q': '3 + 5 = ?', 'a': '8'},\n","]\n","\n","prompt_template = PromptTemplate(\n","    template='Q: {q}\\nA: {a}',\n","    input_variables=['q', 'a']\n",")\n","\n","fewshot_template = FewShotPromptTemplate(\n","    examples=examples,\n","    example_prompt=prompt_template,\n","    prefix='다음 수학문제를 풀어주세요:',\n","    suffix='Q: {question} \\nA:', # 사용자입력값\n","    input_variables=['question']\n",")\n","\n","prompt = fewshot_template.format(question='123 + 345 = ?')\n","print(prompt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EMVfcizf-f5N","executionInfo":{"status":"ok","timestamp":1751005568834,"user_tz":-540,"elapsed":8,"user":{"displayName":"강윤구","userId":"06321173146398152973"}},"outputId":"00c94c7c-8112-4510-850a-f0b362725cb3"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["다음 수학문제를 풀어주세요:\n","\n","Q: 2 + 2 = ?\n","A: 4\n","\n","Q: 3 + 5 = ?\n","A: 8\n","\n","Q: 123 + 345 = ? \n","A:\n"]}]},{"cell_type":"code","source":["print(llm.invoke(prompt).content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ie6sJshaEMCU","executionInfo":{"status":"ok","timestamp":1751005592221,"user_tz":-540,"elapsed":1839,"user":{"displayName":"강윤구","userId":"06321173146398152973"}},"outputId":"37ac8acf-2506-4491-95e8-8a33e844c176"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["A: 468\n"]}]},{"cell_type":"markdown","source":["## Output Parsers\n","\n","https://python.langchain.com/api_reference/langchain/output_parsers.html#module-langchain.output_parsers\n","\n","LangChain의 Output Parsers는 LLM이 생성한 텍스트 출력을 특정 형식으로 변환하거나 처리하는 데 사용된다. 이는 모델의 응답을 해석하고, 이를 구조화된 데이터로 바꿔 후속 작업에 활용하기 위해 설계되었다. Output Parsers는 LangChain의 응답 처리 워크플로우에서 중요한 역할을 한다.\n","\n","예를 들어, LLM 응답이 \"Name: John, Age: 30\"와 같은 텍스트라면, 이를 {\"name\": \"John\", \"age\": 30}과 같은 Python 딕셔너리로 변환 가능.\n","\n","**사용 목적**\n","- 모델의 출력을 특정 애플리케이션에 맞게 처리해야 하는 경우가 많음.\n","- 응답을 해석하는 일관성과 정확성을 높이기 위해 필요.\n","- 텍스트 기반 응답을 JSON, 리스트 또는 숫자와 같은 특정 포맷으로 변환하여 후속 작업에 활용.\n","\n","**종류**\n","1. **BaseOutputParser**: Output Parsers의 기본 클래스, 커스텀 파서 구현 시 사용.  \n","2. **CommaSeparatedListOutputParser**: 콤마로 구분된 문자열을 리스트로 변환.  \n","3. **RegexParser**: 정규식을 사용해 특정 패턴을 추출하고 키-값 형태로 반환.  \n","4. **StructuredOutputParser**: 출력의 JSON 또는 구조화된 형식을 강제.  \n","5. **PydanticOutputParser**: Pydantic 모델을 기반으로 출력 검증 및 변환.  \n","6. **MarkdownOutputParser**: 마크다운 형식의 텍스트에서 데이터를 추출.  "],"metadata":{"id":"IhmUUD1uEwZw"}},{"cell_type":"markdown","source":["### CommaSeparatedListOutputParser"],"metadata":{"id":"JqZF8rDHFFnS"}},{"cell_type":"code","source":["from langchain.output_parsers import CommaSeparatedListOutputParser\n","\n","model_output = \"사과, 바나나, 오렌지, 포도\"\n","\n","output_parser = CommaSeparatedListOutputParser()\n","output = output_parser.parse(model_output)\n","output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mabBWcGaExL_","executionInfo":{"status":"ok","timestamp":1751005988778,"user_tz":-540,"elapsed":15,"user":{"displayName":"강윤구","userId":"06321173146398152973"}},"outputId":"da2cde05-ac18-4849-a4d2-209a87e94bba"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['사과', '바나나', '오렌지', '포도']"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["# {야구}팀 {5}개 질문\n","# {축구}팀 {10}개 질문\n","\n","prompt_template = PromptTemplate(\n","    template=\"{subject} {n}개의 팀을 보여주세요.\\n{format_instruction}\",\n","    input_variables=['subject', 'n'], # 사용자 프롬프트로 채워질 변수\n","    partial_variables={\n","        # template 생성시에 채워짐\n","        'format_instruction': output_parser.get_format_instructions()\n","    }\n",")\n","\n","prompt = prompt_template.format(subject='대한민국 프로야구', n=5)\n","prompt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"id":"HQwkxYTAFwcd","executionInfo":{"status":"ok","timestamp":1751006412101,"user_tz":-540,"elapsed":49,"user":{"displayName":"강윤구","userId":"06321173146398152973"}},"outputId":"ccde0d41-7502-4e29-d4fc-6212b40388bd"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'대한민국 프로야구 5개의 팀을 보여주세요.\\nYour response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["# {야구}팀 {5}개 질문\n","# {축구}팀 {10}개 질문\n","\n","prompt_template = PromptTemplate(\n","    template=\"{subject} {n}개의 팀을 보여주세요.\\n{format_instruction}\",\n","    input_variables=['subject', 'n'], # 사용자 프롬프트로 채워질 변수\n","    partial_variables={\n","        # template 생성시에 채워짐\n","        'format_instruction': output_parser.get_format_instructions()\n","    }\n",")\n","\n","prompt = prompt_template.format(subject='대한민국 프로야구', n=5)\n","prompt = prompt_template.format(subject='프리미어리그', n=5)\n","prompt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"id":"F8Yf_gwpFnzk","executionInfo":{"status":"ok","timestamp":1751006527148,"user_tz":-540,"elapsed":8,"user":{"displayName":"강윤구","userId":"06321173146398152973"}},"outputId":"415b1116-d454-460b-fac7-7981fa27236f"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'프리미어리그 5개의 팀을 보여주세요.\\nYour response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["ai_message = llm.invoke(prompt)\n","output = ai_message.content\n","\n","# 출력파서가 가공한 최종출력\n","output = output_parser.parse(output)\n","output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w3Df_QahHzb4","executionInfo":{"status":"ok","timestamp":1751006553327,"user_tz":-540,"elapsed":2741,"user":{"displayName":"강윤구","userId":"06321173146398152973"}},"outputId":"f8419ca1-f27c-49eb-d832-c62c080ea074"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['맨체스터 시티', '리버풀', '맨체스터 유나이티드', '아스널', '첼시']"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["chain = prompt_template | llm | output_parser\n","chain.invoke(input={'subject':'프로농구', 'n':3})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"keeHpEsFHz7O","executionInfo":{"status":"ok","timestamp":1751008045358,"user_tz":-540,"elapsed":1880,"user":{"displayName":"강윤구","userId":"06321173146398152973"}},"outputId":"797561aa-52d7-4b4d-de70-99fa9ecd81f6"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['서울 SK 나이츠', '전주 KCC 이지스', '인천 전자랜드 엘리펀츠']"]},"metadata":{},"execution_count":28}]},{"cell_type":"markdown","source":["### JSONOutputParser"],"metadata":{"id":"u65Ug9m9NjtV"}},{"cell_type":"code","source":["from langchain_core.output_parsers import JsonOutputParser\n","\n","model_output = '{\"title\": \"GPT-5를 소개합니다.\", \"author\": \"OpenAI\", \"pages\": 250}'\n","\n","json_parser = JsonOutputParser()\n","print(json_parser.get_format_instructions())\n","\n","output = json_parser.parse(model_output) # json_str -> python object(list, dict)\n","print(output)\n","print(type(output))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JGEn1rpmNksD","executionInfo":{"status":"ok","timestamp":1751008045395,"user_tz":-540,"elapsed":33,"user":{"displayName":"강윤구","userId":"06321173146398152973"}},"outputId":"d1debcaf-26e0-49f8-a38b-4cd98926170c"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Return a JSON object.\n","{'title': 'GPT-5를 소개합니다.', 'author': 'OpenAI', 'pages': 250}\n","<class 'dict'>\n"]}]},{"cell_type":"code","source":["# AI 관련 책 3권을 보여주세요. (json)\n","# 요리 관련 책 5권을 보여주세요. (json)\n","# PromptTemplate - LLM - JsonOutputParser\n","\n","prompt_template = PromptTemplate(\n","    template=\"{subject} {n}개의 책을 보여주세요.\\n{format_instruction}\",\n","    input_variables=['subject', 'n'], # 사용자 프롬프트로 채워질 변수\n","    partial_variables={\n","        # template 생성시에 채워짐\n","        'format_instruction': output_parser.get_format_instructions()\n","    }\n",")\n","\n","prompt1 = prompt_template.format(subject='요리', n=5)\n","prompt2 = prompt_template.format(subject='AI', n=3)\n","print(prompt1)\n","print(prompt2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IZW9bequNmZY","executionInfo":{"status":"ok","timestamp":1751008199273,"user_tz":-540,"elapsed":8,"user":{"displayName":"강윤구","userId":"06321173146398152973"}},"outputId":"ec26541d-b5db-4eda-c5c7-a2d8a8213e72"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["요리 5개의 책을 보여주세요.\n","Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\n","AI 3개의 책을 보여주세요.\n","Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\n"]}]},{"cell_type":"code","source":["ai_message1 = llm.invoke(prompt1)\n","ai_message2 = llm.invoke(prompt2)\n","output1 = ai_message1.content\n","output2 = ai_message2.content\n","\n","# 출력파서가 가공한 최종출력\n","output1 = output_parser.parse(output1)\n","output2 = output_parser.parse(output2)\n","print(output1)\n","print(output2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f55_hoE9OAib","executionInfo":{"status":"ok","timestamp":1751008288747,"user_tz":-540,"elapsed":1924,"user":{"displayName":"강윤구","userId":"06321173146398152973"}},"outputId":"897f5f4c-d546-4893-eecf-506a2099321d"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["['요리의 정석', '집밥 백선생', '맛있는 집밥', '고기 구이의 기술', '건강한 심플 레시피']\n","['인공지능의 정석', '딥러닝 입문', '인간과 기계의 미래']\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"JnUUlWW4OMU_"},"execution_count":null,"outputs":[]}]}