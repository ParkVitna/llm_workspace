{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNFZrRfNX1uXYRN4BVr9mEc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Whisper\n","\n","https://openai.com/index/whisper/\n","\n","Whisper는 OpenAI에서 개발한 범용 음성 인식 모델로, 다양한 오디오 데이터셋을 학습하여 다국어 음성 인식, 음성 번역, 언어 식별 등의 작업을 수행할 수 있다.\n","\n","Whisper v2-large 모델은 현재 API를 통해 'whisper-1'이라는 이름으로 제공되고 있다.\n","\n","오픈 소스 버전의 Whisper와 API를 통한 Whisper는 기능적으로 동일하지만, API를 통해 제공되는 버전은 최적화된 추론 과정을 거쳐 다른 방법에 비해 더 빠르게 동작한다."],"metadata":{"id":"SPfIV__o1iRO"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"frHVvaCa1clc","executionInfo":{"status":"ok","timestamp":1750835006128,"user_tz":-540,"elapsed":2865,"user":{"displayName":"이서","userId":"13175179982189425886"}}},"outputs":[],"source":["from google.colab import userdata\n","\n","OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')"]},{"cell_type":"code","source":["from openai import OpenAI\n","\n","client = OpenAI(api_key=OPENAI_API_KEY)\n","\n","file_path = 'output.mp3'\n","\n","with open(file_path, 'rb') as f:\n","    transcription = client.audio.transcriptions.create(\n","        model='whisper-1',\n","        file=f\n","    )\n","\n","print(transcription)\n","print(transcription.text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7d8lFZ7I5epn","executionInfo":{"status":"ok","timestamp":1750835579454,"user_tz":-540,"elapsed":2261,"user":{"displayName":"이서","userId":"13175179982189425886"}},"outputId":"71cb45ee-a933-4a50-c131-135cee65f4b2"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Transcription(text='오늘은 비가 추적추적 오는 여름 어느 날입니다. 이삭토스트 맛있었고요.', logprobs=None, usage={'type': 'duration', 'seconds': 6})\n","오늘은 비가 추적추적 오는 여름 어느 날입니다. 이삭토스트 맛있었고요.\n"]}]},{"cell_type":"markdown","source":["# Embeddings\n","https://platform.openai.com/docs/models#embeddings\n","\n","임베딩(Embeddings)은 텍스트를 수치적으로 표현한 값으로, 두 텍스트 간의 연관성을 측정하는 데 사용된다.\n","\n","임베딩은 검색, 군집화(clustering), 추천 시스템, 이상 탐지, 분류와 같은 작업에 유용하다.\n","\n","**모델 및 출력 차원**\n","\n","| 모델 이름                     | 설명                                                              | 출력 차원 |\n","|-------------------------------|-------------------------------------------------------------------|-----------|\n","| **text-embedding-3-large**   | 영어 및 비영어 작업 모두에서 가장 강력한 성능을 가진 모델           | 3,072     |\n","| **text-embedding-3-small**   | 2세대 ada 임베딩 모델보다 성능이 향상된 모델                        | 1,536     |\n","| **text-embedding-ada-002**   | 1세대 모델 16개를 대체하는 가장 강력한 2세대 임베딩 모델             | 1,536     |"],"metadata":{"id":"SMBhhopX7wCm"}},{"cell_type":"markdown","source":["## MTEB Leaderboard\n","**Massive Text Embedding Benchmark (MTEB) Leaderboard**\n","\n","https://huggingface.co/spaces/mteb/leaderboard\n","\n","**MTEB Leaderboard**는 Hugging Face에서 제공하는 벤치마크 리더보드 페이지로, 다양한 언어 모델(Language Model)과 임베딩 모델(Embedding Model)의 성능을 객관적으로 비교·평가하는 공간이다.\n","\n","**MTEB Leaderboard에서 순위 산정 방식**\n","\n","**MTEB Leaderboard**의 순위는 다양한 자연어 처리 태스크(분류, 클러스터링, 검색, 문장 유사도 등)에서 모델이 얻은 점수들의 평균을 기반으로 산정된다. 즉, 여러 벤치마크 데이터셋에서 모델의 성능을 측정하고, 이를 종합하여 평균 점수를 계산한 뒤, 이 평균 점수가 높은 순서대로 모델이 정렬된다.\n","\n","**주요 평가 방식**\n","\n","- **평가 태스크 종류**\n","  - 분류(Classification): F1 점수\n","  - 클러스터링(Clustering): V-measure\n","  - 쌍 분류(Pair Classification): Average Precision\n","  - 재정렬(Reranking): MRR@k, MAP\n","  - 검색(Retrieval): nDCG@k\n","  - 의미 유사도(STS): Spearman correlation\n","  - 요약(Summarization): Spearman correlation  \n","  각 태스크별로 대표적인 평가 지표가 다르며, 모델은 여러 태스크에서 평가를 받는다[2].\n","\n","- **평균 점수 산정**\n","  - 각 태스크별로 모델이 얻은 점수를 모두 합산한 뒤, 태스크 수로 나누어 평균 점수를 구한다.\n","  - 이 평균 점수가 리더보드의 기본 순위 기준이 된다.\n","\n","- **부분 평가 가능**\n","  - 모든 태스크를 수행하지 않아도 특정 태스크만 평가받아 부분 리더보드에 오를 수 있다. 예를 들어, 클러스터링 태스크만 평가받아 해당 부분 순위에 표시될 수 있다."],"metadata":{"id":"dquQ3CkB9Cz_"}},{"cell_type":"code","source":["from google.colab import OPENAI_API_KEY"],"metadata":{"id":"lIPhUOCz71KL"},"execution_count":null,"outputs":[]}]}