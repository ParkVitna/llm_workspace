{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMRovoKUoII4RmNfA5YKWEQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Function calling\n","\n","https://platform.openai.com/docs/guides/function-calling\n","\n","Function Calling은 OpenAI의 GPT 모델이 특정 작업을 수행할 수 있도록 함수 호출을 지원하는 기능이다.\n","\n","이 기능을 활용하면 GPT 모델이 단순한 텍스트 생성뿐만 아니라 더 복잡한 작업도 자동으로 처리할 수 있다.\n","\n","Function Calling을 통해 다음과 같은 작업을 수행할 수 있다:\n","\n","1. **API 호출**: 외부 API를 호출하여 실시간 데이터를 가져오거나 특정 작업을 수행할 수 있다.  \n","   예) 날씨 정보 조회, 금융 데이터 조회\n","\n","2. **데이터 처리**: 특정 함수를 호출하여 데이터 처리 작업을 수행할 수 있다.  \n","   예) 텍스트 데이터 분석, 통계 계산\n","\n","3. **자동화된 작업**: 여러 단계의 작업을 자동화하여 수행할 수 있다.  \n","   예) 사용자가 요청한 내용을 기반으로 보고서 생성, 이메일 작성\n","\n","**주요 특징**\n","\n","- **함수 정의**: 사전에 정의된 함수나 API 엔드포인트를 GPT 모델에 통합할 수 있다.\n","- **자동 호출**: 사용자가 명시적으로 요청하지 않아도, GPT 모델이 컨텍스트를 이해하고 자동으로 적절한 함수를 호출할 수 있다.\n","- **입출력 처리**: 함수의 입력값을 자동으로 생성하고, 함수 호출 후 반환된 결과를 적절히 처리하여 사용자에게 전달할 수 있다."],"metadata":{"id":"tR_iPscC38AL"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"rifUd8lp35-U"},"outputs":[],"source":["from google.colab import userdata\n","\n","OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n","OPENWEATHER_API_KEY = userdata.get('OPENWEATHER_API_KEY')\n"]},{"cell_type":"markdown","source":["## Function 정의"],"metadata":{"id":"t95TGcHDDFrj"}},{"cell_type":"code","source":["import requests\n","import json\n","\n","def get_current_weather(city,units):\n","  url = f'https://api.openweathermap.org/data/2.5/weather?q={city}&appid={OPENWEATHER_API_KEY}&units={units}'\n","\n","  response = requests.get(url)\n","  data = response.json() # response content(json) 반환\n","\n","  # llm에 전달할 날씨 정보\n","  if response.status_code == 200:\n","    weather_description = data['weather'][0]['description']\n","    temperature = data['main']['temp']\n","    humidity = data['main']['humidity']\n","    weather_info = {\n","        'location' : city,\n","        'weather':weather_description,\n","        'temperature':temperature,\n","        'humidity':humidity,\n","        'unit':'celsius' if units == 'metric' else 'fahrenheit'\n","    }\n","  else:\n","    # api 요청 실패한 경우\n","    weather_info = {\n","        'location' : city,\n","        'weather':'Not Found',\n","        'temperature':'Not Found',\n","        'humidity':'Not Found',\n","        'unit':'Not Found',\n","    }\n","\n","  return json.dumps(weather_info)\n","\n","get_current_weather('Seoul','metric')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"64fr-nuX_eQl","executionInfo":{"status":"ok","timestamp":1750904478374,"user_tz":-540,"elapsed":96,"user":{"displayName":"김광령","userId":"13749192203799061261"}},"outputId":"48c069a2-7ebd-4675-bd7c-bf69cfeaf197"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'{\"location\": \"Seoul\", \"weather\": \"broken clouds\", \"temperature\": 23.79, \"humidity\": 86, \"unit\": \"celsius\"}'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["## LLM 요청 흐름"],"metadata":{"id":"qIliqqCdC4YP"}},{"cell_type":"code","source":["# LLM에게 각 function을 설명하는 메타 정보\n","from openai import OpenAI\n","\n","tools = [{\n","    \"type\": \"function\",\n","    \"function\":{\n","        \"name\": \"get_current_weather\",\n","        \"description\": \"Get current temperature for a given location.\",\n","        \"parameters\": {\n","            \"type\": \"object\",\n","            \"properties\": {\n","                \"city\": {\n","                    \"type\": \"string\",\n","                    \"description\": \"날씨 정보를 얻고자 하는 도시 이름(영문)\"\n","                },\n","                \"units\": {\n","                    \"type\": \"string\",\n","                    \"enum\": [\"metric\", \"imperial\"],\n","                    \"description\": \"날씨에 관한 단위 설정, 섭씨를 사용하는 경우 metric, 화씨를 사용하는 경우 imperial 선택\",\n","                }\n","            },\n","            \"required\": [\n","                \"city\"\n","            ],\n","            \"additionalProperties\": False\n","        }\n","    }\n","}]\n","\n","messages = [\n","    {'role':'system', 'content':'당신은 친절한 챗봇으로 사용자의 요청에 상세히 답변하세요.'},\n","    {'role':'user', 'content':'오늘 서울 날씨를 알려줘'},\n","]\n","client = OpenAI(api_key=OPENAI_API_KEY)\n","\n","response = client.chat.completions.create(\n","    model=\"gpt-4o-mini\",\n","    messages = messages,\n","    tools = tools\n",")\n","\n","response\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bJgORyt6C5d6","executionInfo":{"status":"ok","timestamp":1750907314519,"user_tz":-540,"elapsed":782,"user":{"displayName":"김광령","userId":"13749192203799061261"}},"outputId":"bb7e7b77-450a-456f-c1fc-fe73ed84fd8d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ChatCompletion(id='chatcmpl-BmXGUOLKDJTvme50TR4np6azGmJa3', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_rCp3JevwJCP0OokzPjfmKG6Z', function=Function(arguments='{\"city\":\"Seoul\",\"units\":\"metric\"}', name='get_current_weather'), type='function')]))], created=1750907314, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_34a54ae93c', usage=CompletionUsage(completion_tokens=20, prompt_tokens=122, total_tokens=142, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["# LLM으로부터 받은 정보 확인하는 코드\n","response_message = response.choices[0].message\n","tool_calls = response_message.tool_calls\n","tool_calls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wCkbMxY4HWi0","executionInfo":{"status":"ok","timestamp":1750907322620,"user_tz":-540,"elapsed":18,"user":{"displayName":"김광령","userId":"13749192203799061261"}},"outputId":"35e4cd38-1994-4f03-a5cd-dc7ac8e1b651"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[ChatCompletionMessageToolCall(id='call_rCp3JevwJCP0OokzPjfmKG6Z', function=Function(arguments='{\"city\":\"Seoul\",\"units\":\"metric\"}', name='get_current_weather'), type='function')]"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["# 실행 가능한 함수 목록\n","available_functions = {\n","    \"get_current_weather\": get_current_weather,\n","}\n","\n","# llm function call 응답 tool_calls 추가\n","messages.append(response_message)\n","\n","# 각 함수 실행 및 응답 messages에 추가\n","for tool_call in tool_calls:\n","    function_name = tool_call.function.name\n","    function_to_call = available_functions[function_name]\n","    function_args = json.loads(tool_call.function.arguments)\n","    function_response = function_to_call(**function_args)\n","\n","    print(function_response)\n","\n","    # 응답을 메시지에 추가\n","    messages.append({\n","        'role': 'tool',\n","        'tool_call_id': tool_call.id,\n","        'name': function_name,\n","        'content': function_response\n","    })\n","\n","# messages 확인용 출력\n","messages\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jltc_KuuHwZO","executionInfo":{"status":"ok","timestamp":1750909671141,"user_tz":-540,"elapsed":92,"user":{"displayName":"김광령","userId":"13749192203799061261"}},"outputId":"added06d-60bb-41c0-d32f-71f1a907bcf5","collapsed":true},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["{\"location\": \"Seoul\", \"weather\": \"mist\", \"temperature\": 23.76, \"humidity\": 94, \"unit\": \"celsius\"}\n"]},{"output_type":"execute_result","data":{"text/plain":["[{'role': 'system', 'content': '당신은 친절한 챗봇으로 사용자의 요청에 상세히 답변하세요.'},\n"," {'role': 'user', 'content': '오늘 서울 날씨를 알려줘'},\n"," {'role': 'assistant',\n","  'content': ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_rCp3JevwJCP0OokzPjfmKG6Z', function=Function(arguments='{\"city\":\"Seoul\",\"units\":\"metric\"}', name='get_current_weather'), type='function')])},\n"," {'role': 'function',\n","  'tool_call_id': 'call_rCp3JevwJCP0OokzPjfmKG6Z',\n","  'name': 'get_current_weather',\n","  'content': '{\"location\": \"Seoul\", \"weather\": \"mist\", \"temperature\": 22.76, \"humidity\": 94, \"unit\": \"celsius\"}'},\n"," {'role': 'assistant',\n","  'tool_calls': [ChatCompletionMessageToolCall(id='call_rCp3JevwJCP0OokzPjfmKG6Z', function=Function(arguments='{\"city\":\"Seoul\",\"units\":\"metric\"}', name='get_current_weather'), type='function')]},\n"," {'role': 'tool',\n","  'tool_call_id': 'call_rCp3JevwJCP0OokzPjfmKG6Z',\n","  'name': 'get_current_weather',\n","  'content': '{\"location\": \"Seoul\", \"weather\": \"broken clouds\", \"temperature\": 23.76, \"humidity\": 94, \"unit\": \"celsius\"}'},\n"," {'role': 'assistant',\n","  'tool_calls': [ChatCompletionMessageToolCall(id='call_rCp3JevwJCP0OokzPjfmKG6Z', function=Function(arguments='{\"city\":\"Seoul\",\"units\":\"metric\"}', name='get_current_weather'), type='function')]},\n"," {'role': 'tool',\n","  'tool_call_id': 'call_rCp3JevwJCP0OokzPjfmKG6Z',\n","  'name': 'get_current_weather',\n","  'content': '{\"location\": \"Seoul\", \"weather\": \"mist\", \"temperature\": 23.76, \"humidity\": 94, \"unit\": \"celsius\"}'},\n"," {'role': 'assistant',\n","  'tool_calls': [ChatCompletionMessageToolCall(id='call_rCp3JevwJCP0OokzPjfmKG6Z', function=Function(arguments='{\"city\":\"Seoul\",\"units\":\"metric\"}', name='get_current_weather'), type='function')]},\n"," {'role': 'tool',\n","  'tool_call_id': 'call_rCp3JevwJCP0OokzPjfmKG6Z',\n","  'name': 'get_current_weather',\n","  'content': '\"{\\\\\"location\\\\\": \\\\\"Seoul\\\\\", \\\\\"weather\\\\\": \\\\\"broken clouds\\\\\", \\\\\"temperature\\\\\": 23.76, \\\\\"humidity\\\\\": 94, \\\\\"unit\\\\\": \\\\\"celsius\\\\\"}\"'},\n"," {'role': 'assistant',\n","  'tool_calls': [ChatCompletionMessageToolCall(id='call_rCp3JevwJCP0OokzPjfmKG6Z', function=Function(arguments='{\"city\":\"Seoul\",\"units\":\"metric\"}', name='get_current_weather'), type='function')]},\n"," {'role': 'tool',\n","  'tool_call_id': 'call_rCp3JevwJCP0OokzPjfmKG6Z',\n","  'name': 'get_current_weather',\n","  'content': '\"{\\\\\"location\\\\\": \\\\\"Seoul\\\\\", \\\\\"weather\\\\\": \\\\\"mist\\\\\", \\\\\"temperature\\\\\": 23.76, \\\\\"humidity\\\\\": 94, \\\\\"unit\\\\\": \\\\\"celsius\\\\\"}\"'},\n"," ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_rCp3JevwJCP0OokzPjfmKG6Z', function=Function(arguments='{\"city\":\"Seoul\",\"units\":\"metric\"}', name='get_current_weather'), type='function')]),\n"," {'role': 'tool',\n","  'tool_call_id': 'call_rCp3JevwJCP0OokzPjfmKG6Z',\n","  'name': 'get_current_weather',\n","  'content': '{\"location\": \"Seoul\", \"weather\": \"mist\", \"temperature\": 23.76, \"humidity\": 94, \"unit\": \"celsius\"}'}]"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["# 최종 llm 응답\n","response = client.chat.completions.create(\n","    model=\"gpt-4o-mini\",\n","    messages = messages,\n",")\n","\n","response.choices[0].message.content\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":459},"id":"Qxng4-6NNWmT","executionInfo":{"status":"error","timestamp":1750909675412,"user_tz":-540,"elapsed":488,"user":{"displayName":"김광령","userId":"13749192203799061261"}},"outputId":"34ad0cba-144b-4791-ca02-b054abe17786"},"execution_count":28,"outputs":[{"output_type":"error","ename":"BadRequestError","evalue":"Error code: 400 - {'error': {'message': \"Invalid type for 'messages[2].content': expected one of a string or array of objects, but got an object instead.\", 'type': 'invalid_request_error', 'param': 'messages[2].content', 'code': 'invalid_type'}}","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-28-49143695.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 최종 llm 응답\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m response = client.chat.completions.create(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-4o-mini\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmessages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/resources/chat/completions/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    923\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m    924\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    926\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             body=maybe_transform(\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1247\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m         )\n\u001b[0;32m-> 1249\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m     def patch(\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"Invalid type for 'messages[2].content': expected one of a string or array of objects, but got an object instead.\", 'type': 'invalid_request_error', 'param': 'messages[2].content', 'code': 'invalid_type'}}"]}]},{"cell_type":"code","source":["# tool_call을 포함한 함수\n","def run_conversation(prompt):\n","  messages = [\n","      {'role':'system', 'content':'당신은 친절한 챗봇으로 사용자의 요청에 상세히 답변하세요.'},\n","      {'role':'user', 'content':prompt},\n","  ]\n","  client = OpenAI(api_key=OPENAI_API_KEY)\n","\n","  # 첫번째 LLM 요청\n","  response = client.chat.completions.create(\n","      model=\"gpt-4o-mini\",\n","      messages = messages,\n","      tools = tools\n","  )\n","  # 첫번째 LLM 응답 확인\n","  response_message = response.choices[0].message\n","  tool_calls = response_message.tool_calls\n","\n","  # tool_call이 필요한 경우와 아닌 경우 분기\n","  if tool_calls:\n","    messages.append(response_message)\n","\n","    # 각 함수 실행 및 응답 messages에 추가\n","    for tool_call in tool_calls:\n","        function_name = tool_call.function.name\n","        function_to_call = available_functions[function_name]\n","        function_args = json.loads(tool_call.function.arguments)\n","        function_response = function_to_call(**function_args)\n","\n","        messages.append({\n","            'role': 'tool',\n","            'tool_call_id': tool_call.id,\n","            'name': function_name,\n","            'content': function_response\n","        })\n","\n","      # 두 번째 LLM 요청\n","    response = client.chat.completions.create(\n","    model=\"gpt-4o-mini\",\n","    messages = messages,\n","    )\n","\n","  return response.choices[0].message.content\n","run_conversation('밥 먹었니?')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"nDRqjkE5UBFF","executionInfo":{"status":"ok","timestamp":1750909751552,"user_tz":-540,"elapsed":1278,"user":{"displayName":"김광령","userId":"13749192203799061261"}},"outputId":"09679692-abf6-4684-b6a6-57c9d0472020"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'저는 음식이 필요 없지만, 여러분의 식사 시간은 어떤지 궁금하네요! 오늘 어떤 음식을 드셨나요?'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":29}]}]}