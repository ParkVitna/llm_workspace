{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyP7/3iaH/G3XAaPEz0tJiDa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Chat Completions API\n","\n","Chat Completions API는 OpenAI에서 제공하는 대화형 인공지능 모델(GPT 계열)을 활용해, 사용자의 메시지에 대해 자연스러운 대화 응답을 생성하는 API이다. 이 API는 챗봇, AI 비서, 자동화된 상담 시스템 등 다양한 대화형 서비스에 적용할 수 있다.\n","\n","\n","- **대화 문맥 유지**  \n","  Chat Completions API는 여러 메시지(대화 내역)를 입력받아, 이전 대화의 맥락을 이해하고 그에 맞는 응답을 생성한다. 즉, 단순히 한 문장만을 이어 쓰는 것이 아니라, 대화의 흐름을 반영하여 자연스러운 대화를 이어갈 수 있다.\n","\n","- **역할(Role) 기반 메시지 구조**  \n","  입력 메시지는 배열 형태로 전달하며, 각 메시지는 `role`과 `content`로 구성된다.  \n","  - `system`: AI의 태도, 성격, 역할을 정의(예: \"너는 친절한 도우미야.\")\n","  - `user`: 사용자의 질문이나 요청\n","  - `assistant`: AI의 응답(이전 대화 내용 포함 가능)\n","  \n","  이 구조를 통해 AI의 응답 스타일이나 맥락을 세밀하게 제어할 수 있다[1][3][5].\n","\n","**주요 파라미터 설명**\n","\n","| 파라미터        | 설명                                                                 |\n","|----------------|----------------------------------------------------------------------|\n","| model          | 사용할 언어 모델명 (예: gpt-3.5-turbo, gpt-4o 등)                    |\n","| messages       | 대화 내역(역할/내용 포함) 배열                                        |\n","| max_tokens     | 생성할 응답의 최대 토큰 수(선택)                                     |\n","| temperature    | 창의성 조절(0~2, 낮을수록 일관성↑, 높을수록 다양성↑, 선택)           |\n","| top_p          | 누적 확률 기반 샘플링(temperature와 유사, 선택)                      |\n","| n              | 한 번에 생성할 응답 개수(선택)                                       |\n","| stop           | 응답 생성을 중단할 문자열 목록(선택)                                 |\n","| presence_penalty, frequency_penalty | 반복 억제 및 창의성 유도(선택)                 |\n","| user           | 사용자 식별자(선택, abuse monitoring 등 활용)                        |\n","\n","\n","- 위 예시에서 `messages` 배열에는 대화의 모든 메시지가 순서대로 들어가야 한다.  \n","- OpenAI는 이전 요청을 기억하지 않기 때문에, 매 API 호출마다 대화 내역 전체를 함께 보내야 한다.\n"],"metadata":{"id":"nTb6ssk28Iky"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"KectF_LX8D_X","executionInfo":{"status":"ok","timestamp":1750819239622,"user_tz":-540,"elapsed":888,"user":{"displayName":"wars dream","userId":"01106558185160796091"}}},"outputs":[],"source":["from google.colab import userdata\n","import os\n","from openai import OpenAI\n","\n","# OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")\n","# client = OpenAI(api_key=OPENAI_API_KEY)\n","\n","# 환경변수 지정\n","os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n","client = OpenAI()"]},{"cell_type":"markdown","source":["## 대화형 챗봇"],"metadata":{"id":"fSUemmDX9p5a"}},{"cell_type":"code","source":["response = client.chat.completions.create(\n","    model='gpt-4.1-nano',\n","    messages=[\n","        {'role': 'system', 'content': '너는 친절한 챗봇입니다.'},\n","        {'role': 'user', 'content': '안녕, 내 이름은 차은우야~'},\n","        {'role': 'assistant', 'content': '안녕하세요, 차은우님! 만나서 반가워요. 어떻게 도와드릴까요?'},\n","        {'role': 'user', 'content': '잘 지냈어? 내 이름 기억하니?'},\n","    ]\n",")\n","print(response.choices[0].message.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1-AODVEU8qF-","executionInfo":{"status":"ok","timestamp":1750819766177,"user_tz":-540,"elapsed":1396,"user":{"displayName":"wars dream","userId":"01106558185160796091"}},"outputId":"52aae946-787e-4447-8161-115520c867f6"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["네, 차은우님! 이름을 기억하고 있어요. 잘 지내셨어요? 최근에 어떤 일들이 있었는지 궁금하네요.\n"]}]},{"cell_type":"code","source":["response = client.chat.completions.create(\n","    model='gpt-4.1-nano',\n","    messages=[\n","        {'role': 'system', 'content': '너는 LLM 전문가입니다.'},\n","        {'role': 'user', 'content': '안녕, 나는 LLM 꿈나무 차은우야~'},\n","        {'role': 'assistant', 'content': '안녕하세요, 차은우님! LLM 꿈나무라니 멋지네요! 어떤 부분에 대해 이야기하고 싶으신가요? LLM에 대한 질문이나 궁금한 점이 있다면 언제든지 말씀해 주세요.'},\n","        {'role': 'user', 'content': 'Transformer모델을 공부하고 싶어.'},\n","        {'role': 'assistant', 'content': \"\"\"좋아요! Transformer 모델은 자연어 처리(NLP) 분야에서 매우 중요한 혁신을 가져온 아키텍처입니다. 기본적인 구조와 작동 원리를 설명해드릴게요.\n","\n","### 1. Transformer의 기본 구조\n","Transformer는 크게 두 가지 부분으로 구성되어 있습니다: **인코더(Encoder)**와 **디코더(Decoder)**.\n","\n","- **인코더**: 입력 문장을 처리하고, 문장의 의미를 포착하는 고차원 표현을 생성합니다.\n","- **디코더**: 인코더의 출력을 바탕으로 출력 문장을 생성합니다. 주로 번역, 텍스트 요약 등에 사용됩니다.\n","\n","### 2. 자기 주의 메커니즘 (Self-Attention)\n","Transformer의 핵심 개념 중 하나는 자기 주의 메커니즘입니다. 이는 입력 시퀀스 내의 단어들이 서로에게 얼마나 주의를 기울이는지를 학습하는 방법입니다. 이를 통해 문맥을 더 잘 이해할 수 있습니다.\n","\n","### 3. 포지셔널 인코딩 (Positional Encoding)\n","Transformers는 순차적인 정보를 처리하지 않기 때문에 단어의 순서를 이해하기 위한 포지셔널 인코딩을 사용합니다. 이를 통해 단어의 위치 정보를 추가합니다.\n","\n","### 4. 다중 헤드 주의 (Multi-head Attention)\n","Transformer는 하나의 자기 주의 메커니즘 대신 여러 개의 주의 헤드를 사용하여 서로 다른 표현을 학습합니다. 각 헤드는 다른 부분에 초점을 맞출 수 있어 정보의 다양성을 높입니다.\n","\n","### 5. 피드포워드 신경망\n","각 인코더와 디코더의 구조에는 자기 주의 레이어 뒤에 위치한 피드포워드 신경망이 있습니다. 이는 각 단어의 표현을 독립적으로 처리하는 역할을 합니다.\n","\n","### 6. Layer Normalization & Residual Connections\n","모든 레이어에는 레이어 정규화와 잔차 연결이 포함되어 있어, 훈련이 더 쉽게 이루어지도록 돕습니다.\n","\n","### 학습 방법\n","Transformer 모델은 대량의 데이터를 통해 사전 학습(pre-training)되고, 특정 작업에 대해 미세 조정(fine-tuning)됩니다. 여러 가지 변종이 있으며, BERT, GPT 같은 모델들이 이 구조를 기반으로 하고 있습니다.\n","\n","이해가 잘 되셨나요? 더 궁금한 부분이나 구체적인 질문이 있다면 말씀해 주세요!\n","\"\"\"},\n","        {'role': 'user', 'content': '어려워~ 어텐션을 초등학생도 이해할 수 있게 설명해줘.'},\n","        {'role': 'assistant', 'content': \"\"\"물론이죠! 어텐션(attention)을 초등학생도 이해할 수 있게 쉽게 설명해볼게요.\n","\n","### 어텐션을 설명하는 이야기\n","\n","상상해보세요! 여러분이 친구들과 함께 학교에서 이야기를 나누고 있다고 합시다. 그 많은 친구들 중에서 누군가가 아주 중요한 이야기를 하고 있어요. 여러분은 그 친구의 말을 잘 듣고 싶어서 그 친구에게 집중합니다. 반면, 주변의 다른 소리나 대화는 잘 듣지 않으려고 해요. 이런 식으로 우리는 중요한 정보에 주의를 기울이고, 다른 것들은 잠깐 잊어버리는 거예요.\n","\n","### 어텐션은 같아요!\n","\n","어텐션은 컴퓨터가 텍스트를 읽을 때 어떻게 중요한 단어에 집중하는지를 설명하는 방법이에요. 예를 들어, \"내가 어제 강아지와 함께 놀았어요\"라는 문장이 있다고 해볼까요. 이 문장에서 \"강아지\"라는 단어는 이야기에 중요한 부분이에요. 어텐션 메커니즘은 이 \"강아지\"라는 단어에 더 많은 주의를 기울이고, 나머지 단어는 그만큼 덜 신경 쓰는 거죠.\n","\n","### 간단한 예시\n","\n","이제 조금 더 구체적인 예를 들어볼게요. 만약 여러분이 \"사과는 빨갛고 맛있다\"라는 문장을 읽고 있을 때, 어텐션은 \"사과\"라는 단어에 특히 주목하게 해요. 왜냐하면 이 단어가 문장에서 가장 중요한 의미를 갖고 있기 때문이죠.\n","\n","어텐션은 이처럼 중요한 정보를 찾아내어 컴퓨터가 더 똑똑하게 텍스트를 이해하도록 도와주는 역할을 해요.\n","\n","이해가 안 되거나 더 알고 싶은 부분이 있다면 언제든지 물어보세요!\n","\"\"\"},\n","        {'role':'user', 'content':'이해가 되는 것 같아. 트랜스포머 내역을 하나의 markdown문서로 정리해줘'}\n","    ]\n",")\n","print(response.choices[0].message.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KE12LdjX_Xkm","executionInfo":{"status":"ok","timestamp":1750822636778,"user_tz":-540,"elapsed":5919,"user":{"displayName":"wars dream","userId":"01106558185160796091"}},"outputId":"faf9a36f-e031-483b-a319-6a46220e699e"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["물론입니다! 아래에 Transformer 모델의 핵심 내용을 하나의 Markdown 문서로 정리해 드리겠습니다.\n","\n","```markdown\n","# Transformer 모델 개요\n","\n","## 1. 개요\n","Transformer는 자연어 처리(NLP)에서 널리 사용되는 딥러닝 아키텍처로, 2017년 Vaswani et al.이 제안했습니다. 순차적인 데이터를 처리하는 RNN과 달리 병렬 처리가 가능하며, 자기 주의(Self-Attention) 메커니즘을 핵심으로 합니다.\n","\n","---\n","\n","## 2. 주요 구성 요소\n","\n","### 2.1 인코더(Encoder)\n","- 입력 시퀀스를 처리하여 문맥 정보를 담은 벡터로 변환.\n","- 여러 개의 동일한 인코더 층으로 구성됨.\n","\n","### 2.2 디코더(Decoder)\n","- 인코더의 출력과 이전 단어 정보를 바탕으로 다음 단어를 생성.\n","- 여러 개의 동일한 디코더 층으로 구성됨.\n","\n","---\n","\n","## 3. 핵심 기술\n","\n","### 3.1 자기 주의(Self-Attention)\n","- 입력 시퀀스 내의 모든 단어들이 서로에게 얼마나 집중할지 계산.\n","- 문맥 이해를 돕고, 연산 병렬성을 높임.\n","\n","### 3.2 포지셔널 인코딩(Positional Encoding)\n","- 단어의 순서 정보를 제공.\n","- 각 단어 위치에 대한 고유한 벡터를 더하여 위치 정보를 전달.\n","\n","### 3.3 다중 헤드 주의(Multi-Head Attention)\n","- 여러 개의 주의 헤드를 병렬로 사용.\n","- 각 헤드는 다른 부분에 집중하여 다양하고 풍부한 문맥 정보를 학습.\n","\n","### 3.4 피드포워드 네트워크(Feed-Forward Networks)\n","- 각 인코더/디코더 층 내에서 선형 변환 후 비선형 활성화.\n","- 각 단어별 독립적 처리.\n","\n","---\n","\n","## 4. 기타 기술 요소\n","- **Residual Connections (잔차 연결)**: 정보 손실 방지 및 학습 안정화.\n","- **Layer Normalization (레이어 정규화)**: 학습 속도와 성능 향상.\n","- **Dropout**: 과적합 방지.\n","\n","---\n","\n","## 5. Transformer의 흐름 (간단한 단계)\n","\n","1. **입력 단어 임베딩 + 위치 인코딩** → 인코더의 첫 층\n","2. **자기 주의 계산** → 각 단어가 다른 단어에 얼마나 집중할지 결정\n","3. **피드포워드 네트워크** → 각 단어 독립적 처리\n","4. **이 과정을 여러 층 쌓기**\n","5. **인코더 마지막 출력** → 디코더의 입력으로 사용\n","6. **디코더** 내 유사한 프로세스 수행 후 출력 생성\n","\n","---\n","\n","## 6. Transformer의 변화와 발전\n","- **BERT**: 양방향 컨텍스트, 이해 중심\n","- **GPT**: 단방향, 생성 중심\n","- **T5, XLNet**: 다양한 확장과 조합\n","\n","---\n","\n","## 7. 결론\n","Transformer는 병렬 처리가 가능하면서도 강력한 문맥 이해 능력을 갖춘 모델로, 이후 많은 NLP 모델의 기반이 되었어요.\n","\n","---\n","\n","필요하시면 더 상세한 내용이나 그림도 만들어드릴 수 있어요! 궁금한 점 있나요?\n","```\n"]}]},{"cell_type":"markdown","source":["## 반복처리"],"metadata":{"id":"AO-qm0d6KT66"}},{"cell_type":"code","source":["# 대화내역을 로깅\n","messages = [{\n","    'role': 'system', 'content': '너는 친절한 챗봇이다.'}\n","]\n","\n","print('종료하려면, exit를 입력하세요...')\n","while True:\n","    # 사용자 입력\n","    user_input = input('User: ')\n","\n","    if user_input.strip().lower() == 'exit':\n","        print('채팅을 종료합니다.')\n","        break\n","\n","    # messages에 사용자 입력 추가\n","    messages.append(({'role': 'user', 'content': user_input}))\n","\n","    # LLM 요청\n","    response = client.chat.completions.create(\n","        model='gpt-4.1-nano',\n","        messages=messages,\n","        temperature=0.7\n","    )\n","    assistant_message = response.choices[0].message.content\n","    print(f'Assistant: {assistant_message}')\n","\n","    # messages 챗봇 출력 추가\n","    messages.append({'role': 'assistant', 'content': assistant_message})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Da4YZp5bKbFi","executionInfo":{"status":"ok","timestamp":1750822884188,"user_tz":-540,"elapsed":3084,"user":{"displayName":"wars dream","userId":"01106558185160796091"}},"outputId":"1468a2d7-e2cc-4a54-8134-5ab9be541757"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["종료하려면, exit를 입력하세요...\n","User: dfsa\n","[{'role': 'system', 'content': '너는 친절한 챗봇이다.'}, {'role': 'user', 'content': 'dfsa'}]\n","User: exit\n","채팅을 종료합니다.\n"]}]},{"cell_type":"markdown","source":["## stream"],"metadata":{"id":"weQ_RahqNAyi"}},{"cell_type":"code","source":["stream = client.chat.completions.create(\n","    model='gpt-4.1-nano',\n","    messages=[{'role': 'user', 'content': '지금 stream테스트 할 거야, 아주 긴 응답 메세지를 보내줘.'}],\n","    stream=True\n",")\n","for chunk in stream:\n","    content = chunk.choices[0].delta.content\n","    if content is not None:\n","        print(content, end='')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ide1qVeiM_s6","executionInfo":{"status":"ok","timestamp":1750824851515,"user_tz":-540,"elapsed":7274,"user":{"displayName":"wars dream","userId":"01106558185160796091"}},"outputId":"e5098197-529e-47ed-df8c-d8c3c59edef4"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["물론입니다! 지금부터 아주 긴 응답 메시지를 보내드릴게요. 아래 내용을 잘 읽어보시기 바랍니다.\n","\n","---\n","\n","안녕하세요! 지금 스트림 테스트를 위해 긴 응답 메시지를 보내드리고 있습니다. 이 메시지는 여러 문단과 상세한 설명, 그리고 다양한 예제들을 포함하고 있어요. 이렇게 긴 메시지를 통해서 스트림 시스템이 어떤 식으로 데이터를 처리하는지, 그리고 얼마나 안정적이고 연속적으로 데이터를 전달할 수 있는지 테스트할 수 있습니다.\n","\n","먼저, 스트림 스트리밍 기술에 대한 기본 설명부터 시작해보겠습니다. 스트림 스트리밍은 데이터 또는 미디어 콘텐츠를 실시간으로 또는 거의 실시간에 가깝게 전송하는 기술로, 사용자 경험을 향상시키는 데 매우 중요한 역할을 합니다. 예를 들어, 음악 앱에서 곡이 재생되는 동안 다음 곡의 데이터가 동시에 다운로드되거나, 동영상 스트리밍 서비스에서 영상이 끊기지 않고 계속 재생될 수 있는 원리라고 할 수 있죠. 이는 데이터 블록들이 연속적으로 작은 단위로 전달되기 때문에 가능하며, 네트워크 상태에 따라 적절하게 버퍼링과 오류 수정 기법이 함께 적용됩니다.\n","\n","이제 좀 더 구체적인 내용을 살펴보겠습니다. 스트림 처리는 크게 세 가지 단계로 나뉩니다. 첫째, 데이터 생성 또는 수집 단계입니다. 여기서는 원천 데이터가 생성되거나 수집되고, 이를 일정한 크기의 '패킷' 또는 '조각'으로 나누는 과정이 이루어집니다. 둘째, 데이터 전송 단계에서는 이러한 패킷들이 네트워크를 통해 전달됩니다. 이 단계에서는 라우팅, 오류 수정, 재전송 요청 등 복잡한 작업들이 이루어지며, 특히 불안정한 네트워크 환경에서도 안정성을 확보하는 것이 매우 중요합니다. 셋째, 마지막으로 데이터 수신 및 재생 단계에서는 도착한 데이터 패킷이 올바른 순서로 조합되고, 재생하거나 저장하는 과정이 진행됩니다.\n","\n","이와 관련된 기술로는 TCP와 UDP 등이 있는데요, TCP는 안정성을 강조하는 프로토콜로, 데이터 손실 없이 전송을 보장하지만 약간의 지연이 발생할 수 있습니다. 반면 UDP는 속도를 우선시하여 빠른 전송이 가능하지만, 손실이 발생할 수 있어 실시간 스트리밍에 주로 사용됩니다. 또 다른 중요한 개념은 버퍼링과 적응적 비트레이트(Adaptive Bitrate) 기술입니다. 버퍼는 재생 안정성을 위해 미리 일정 시간 데이터를 저장하는 역할을 하며, 인터넷 환경 변화에 따라 비트레이트를 조절하는 기술은 사용자 경험을 향상시키는 핵심 요소입니다.\n","\n","예를 들어, 인터넷 연결이 일시적으로 느려지면 비디오 플레이어는 자동으로 낮은 화질로 전환해 끊김 없이 재생을 지속할 수 있습니다. 이는 사용자에게 자연스러운 시청 경험을 제공하는 중요한 기술적 전략입니다. 또한, 동시다발적인 사용자 요청이 많은 서비스에서는 분산 서버와 CDN(Content Delivery Network)을 활용하여 지리적 위치에 상관없이 빠르고 안정적인 데이터 전달이 가능하도록 설계되곤 합니다.\n","\n","이제 실제 스트림 테스트용 메시지를 계속 보내드리겠습니다. 이 메시지는 길기 때문에 여러 부분으로 나누어 전송될 것이며, 각 부분마다 중요한 설명과 예제들이 포함되어 있습니다. 예를 들어, 다음과 같은 내용을 포함할 수 있습니다:\n","\n","- 스트리밍 프로토콜의 상세 설명\n","- 버퍼링 메커니즘 및 최적화 방법\n","- 오류 검출 및 재전송 전략\n","- 네트워크 환경별 최적화 기법\n","- 실시간 스트리밍과 온디맨드 스트리밍의 차이점\n","- 다양한 미디어 포맷과 전송 방법\n","\n","이상으로 지금까지 제가 준비한 긴 메시지의 일부분이었습니다. 만약 추가로 설명하거나 특정 주제에 대해 더 깊은 내용을 원하시면 언제든 요청해 주세요. 저의 목표는 최대한 많은 정보를 명확하게 전달하는 것이며, 이 과정에서 스트림 시스템의 이해도와 신뢰성을 높일 수 있습니다.\n","\n","이상입니다! 이제 계속해서 더 긴 메시지와 다양한 내용을 계속해서 전송할 준비가 되어 있습니다. 질문이 있으시면 언제든 말씀해 주세요. 감사합니다!\n","\n","---\n","\n","이 메시지가 테스트 목적에 부합되었기를 바랍니다. 더 필요하시면 계속 요청해 주세요!"]}]},{"cell_type":"code","source":["# stream\n","# 대화내역을 로깅\n","messages = [\n","    {'role': 'system', 'content': '너는 친절한 챗봇이다.'}\n","]\n","\n","print('종료하려면, exit를 입력하세요...')\n","while True:\n","    # 사용자 입력\n","    user_input = input('User: ')\n","\n","    if user_input.strip().lower() == 'exit':\n","        print('채팅을 종료합니다...')\n","        break\n","\n","    # messages에 사용자 입력 추가\n","    messages.append({'role': 'user', 'content': user_input})\n","\n","    # LLM 요청\n","    stream = client.chat.completions.create(\n","        model='gpt-4.1-nano',\n","        messages=messages,\n","        temperature=0.7,\n","        stream=True\n","    )\n","    print(f'Assistant: ', end='')\n","    for chunk in stream:\n","        content = chunk.choices[0].delta.content\n","        if content is not None:\n","            print(content, end='' ,flush=True) # 내부 buffer 사용하지 않음\n","    print()\n","\n","    # messages 챗봇 출력 추가\n","    messages.append({'role': 'assistant','content': assistant_message})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"72nYjDPGS0lr","executionInfo":{"status":"ok","timestamp":1750825414875,"user_tz":-540,"elapsed":4760,"user":{"displayName":"wars dream","userId":"01106558185160796091"}},"outputId":"d4013a83-c3b5-4689-a594-7690dff4dd17"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["종료하려면, exit를 입력하세요...\n","User: exit\n","채팅을 종료합니다...\n"]}]},{"cell_type":"markdown","source":["# Token counting\n","\n","비용 = ((입력 토큰 수 * 단가) * (출력 토큰 수 * 단가)) * 월 서비스 호출 수"],"metadata":{"id":"fWG2nmHOU5gk"}},{"cell_type":"code","source":["!pip install tiktoken"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DVyOLJpxVMEJ","executionInfo":{"status":"ok","timestamp":1750825517561,"user_tz":-540,"elapsed":9904,"user":{"displayName":"wars dream","userId":"01106558185160796091"}},"outputId":"cc9866f1-e3fc-4e9a-cd0d-83f8fcde4621"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.6.15)\n"]}]},{"cell_type":"code","source":["# 각 모델에 따른 토커나이져(인코딩) 가져오기\n","import tiktoken\n","\n","gpt35 = tiktoken.encoding_for_model('gpt-3.5')\n","gpt4o = tiktoken.encoding_for_model('gpt-4o')\n","# gpt4o = tiktoken.encoding_for_model('gpt-4.1')\n","gpt41 = tiktoken.get_encoding('cl100k_base')\n","\n","print(gpt35)\n","print(gpt4o)\n","print(gpt41)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VsHfXak7WMTb","executionInfo":{"status":"ok","timestamp":1750825901314,"user_tz":-540,"elapsed":16,"user":{"displayName":"wars dream","userId":"01106558185160796091"}},"outputId":"1e33a796-2882-4d8d-df39-77d628dbaa2e"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["<Encoding 'cl100k_base'>\n","<Encoding 'o200k_base'>\n","<Encoding 'cl100k_base'>\n"]}]},{"cell_type":"code","source":["# 토큰수 세기\n","encoded_gpt35 = gpt35.encode('아버지가 방에 들어가신다.')\n","encoded_gpt4o = gpt4o.encode('아버지가 방에 들어가신다.')\n","\n","print(len(encoded_gpt35))\n","print(len(encoded_gpt4o))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H-mf5okkWNL-","executionInfo":{"status":"ok","timestamp":1750825804082,"user_tz":-540,"elapsed":15,"user":{"displayName":"wars dream","userId":"01106558185160796091"}},"outputId":"bdc0126b-06e6-4d84-e831-73880e89b070"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["13\n","10\n"]}]},{"cell_type":"markdown","source":["## 토큰 비용 계산하기"],"metadata":{"id":"0JoDCiHcW6bS"}},{"cell_type":"code","source":["text = \"\"\"\n","더불어민주당이 6일 한동훈 국민의힘 대표가 윤석열 대통령 탄핵에 사실상 찬성 입장을 시사하자 7일로 예정됐던 윤석열 대통령의 탄핵소추안 표결을 앞당기는 방안을 고심하고 있다. 이재명 민주당 대표는 “한 대표의 입장을 정확하게 파악하는 것이 우선”이라며 신중한 태도를 보였다.\n","\n","이 대표는 이날 기자들을 만나 윤 대통령 탄핵 표결을 앞당기는 방안에 대해 “지금 저렇게 불확실한 얘기를 믿고 미리 당겨서 협의를 할 필요가 있는가, 그런 생각이 일단 든다”고 말했다. 한 대표와의 회동 가능성에 대해서는 “요청은 했는데 아직 결정을 통보받지 못했다. (한 대표 측에서) 오후에 다시 연락하자는 연락이 왔다”고 전했다.\n","\n","이 대표는 또 “사실 오늘 밤이 저는 매우 위험하다고 생각이 드는데, 제가 가진 감으로 본다면 오늘 밤 새벽에 또 뭔가 일을 벌이지 않을까 그런 걱정이 들긴 한다”며 ‘2차 계엄’ 가능성을 우려했다.\n","\n","민주당은 이날 오전 한동훈 대표가 “윤 대통령의 조속한 직무 집행 정지가 필요하다”며 입장을 선회하자 긴급 의원총회를 열고 당내 의견 수렴에 나섰다. 의원총회에서는 탄핵소추안 표결 시점을 앞당기는 방안도 논의될 전망이다.\n","\n","노종면 원내대변인은 비공개 최고위원 간담회가 끝난 뒤 “한 대표의 입장이 보도된 이후 긴장감이 높아지고 있고, 12월 3일 당일에 짐작했던 것 이상으로 치밀하게 의원, 정치인 체포 시도가 있었던 것과 이번 내란 사태에서 매우 중요한 작전이었던 걸로 파악되고 있다”며 “윤 대통령 옹위 세력이 어떻게 나올지 모르는 상황이라고 판단해 이런 비상한 상황 인식 떄문에 긴급 의원총회를 소집했다”고 전했다.\n","\n","탄핵소추안 표결 시점 변경에 대해서는 “의장실에 본회의 일정 변경을 요청한 바는 아직 없다”며 “일단 신중하고 침착하게 대응할 것이고, 지금 한 대표 쪽의 입장이 뭔지 정확하게 파악하는 것이 우선이다. 필요하면 본회의를 앞당기는 방안도 의장실과 협조해서 추진할 수 있지만 아직은 결정된 바 없다”고 밝혔다.\n","\n","민주당에서는 7일 오후 7시로 예정됐던 표결을 2시간 당겨 오후 5시에 추진하는 방안도 거론된다. 박성준 원내운영수석부대표는 이날 MBC 라디오 ‘김종배의 시선집중’ 인터뷰에서 “당초 오후 7시 정도 표결을 예상했는데 5시 정도는 해야 한다고 보고 있다”며 “국민의힘에서 탄핵소추안 투표 관련 상당한 지연 전략을 펼쳐서 시간을 늦출 수 있는 상황까지 고려하고 있다”고 설명했다.\n","\"\"\"\n","\n","encoded_text_gpt4o = gpt4o.encode(text)\n","encoded_text_gpt41 = gpt41.encode(text)\n","\n","print(\"gpt-4o 토큰수: \", len(encoded_text_gpt4o))\n","print(\"gpt-4.1 토큰수: \", len(encoded_text_gpt41))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CbjhmMJNW5ya","executionInfo":{"status":"ok","timestamp":1750826188172,"user_tz":-540,"elapsed":73,"user":{"displayName":"wars dream","userId":"01106558185160796091"}},"outputId":"137d3ff8-bf5a-43bb-8bef-e328c48ffb91"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["gpt-4o 토큰수:  703\n","gpt-4.1 토큰수:  1215\n"]}]},{"cell_type":"code","source":["response_gpt4o = client.chat.completions.create(\n","    model='gpt-4o',\n","    messages=[\n","        {'role': 'system', 'content': '너는 똑부러지는 시사/경제 전문가로써, 제공된 뉴스기사의 핵심을 잘 요약해서 정리해주는 챗봇이야.'},\n","        {'role': 'user', 'content': text}\n","    ],\n","    temperature=.2\n",")\n","\n","response_gpt41 = client.chat.completions.create(\n","    model='gpt-4.1',\n","    messages=[\n","        {'role': 'system', 'content': '너는 똑부러지는 시사/경제 전문가로써, 제공된 뉴스기사의 핵심을 잘 요약해서 정리해주는 챗봇이야.'},\n","        {'role': 'user', 'content': text}\n","    ],\n","    temperature=.2\n",")\n","\n","output_gpt4o = response_gpt4o.choices[0].message.content\n","output_gpt41 = response_gpt41.choices[0].message.content\n","\n","print(\"gpt-4o 응답: \", output_gpt4o)\n","print(\"gpt-4.1 응답: \", output_gpt41)\n","\n","print('\\n', 'gpt-4o 토큰수: ', len(gpt4o.encode(output_gpt4o)))\n","print('gpt-4.1 토큰수: ', len(gpt41.encode(output_gpt41)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bUPgh89YX3w8","executionInfo":{"status":"ok","timestamp":1750826852211,"user_tz":-540,"elapsed":11894,"user":{"displayName":"wars dream","userId":"01106558185160796091"}},"outputId":"5e72af9e-955c-4714-8c16-7591ca0b963a"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["gpt-4o 응답:  더불어민주당은 한동훈 국민의힘 대표가 윤석열 대통령 탄핵에 사실상 찬성하는 입장을 시사하자, 7일로 예정된 탄핵소추안 표결을 앞당기는 방안을 검토하고 있습니다. 이재명 민주당 대표는 한 대표의 입장을 정확히 파악하는 것이 우선이라며 신중한 태도를 보이고 있습니다. 민주당은 한 대표의 입장 변화에 따라 긴급 의원총회를 열어 당내 의견을 수렴하고 있으며, 표결 시점을 앞당기는 방안도 논의 중입니다. 현재로서는 본회의 일정 변경 요청은 없지만, 필요시 의장실과 협조해 추진할 수 있다고 밝혔습니다. 민주당은 표결을 오후 7시에서 5시로 앞당기는 방안을 고려하고 있으며, 국민의힘의 지연 전략에 대비하고 있습니다.\n","gpt-4.1 응답:  ### 기사 핵심 요약\n","\n","**1. 민주당, 윤석열 대통령 탄핵소추안 표결 시점 앞당기나**\n","- 더불어민주당이 7일로 예정된 윤석열 대통령 탄핵소추안 표결을 앞당기는 방안을 검토 중임.\n","- 한동훈 국민의힘 대표가 “윤 대통령의 조속한 직무 집행 정지가 필요하다”며 사실상 탄핵에 찬성하는 듯한 입장을 시사한 것이 계기.\n","\n","**2. 이재명 대표, 신중한 태도**\n","- 이재명 민주당 대표는 “한동훈 대표의 입장을 정확히 파악하는 것이 우선”이라며 신중한 입장.\n","- 한 대표와의 회동 요청은 했으나 아직 답변을 받지 못함.\n","- ‘2차 계엄’ 등 추가적인 돌발 사태 가능성에 대한 우려도 표명.\n","\n","**3. 민주당, 긴급 의원총회 소집**\n","- 한동훈 대표의 발언 이후 긴급 의원총회 개최, 당내 의견 수렴 중.\n","- 탄핵소추안 표결 시점 앞당기는 방안도 논의.\n","\n","**4. 표결 시점 변경 가능성**\n","- 공식적으로 본회의 일정 변경 요청은 아직 없음.\n","- 필요시 본회의를 앞당기는 방안도 검토 중.\n","- 7일 오후 7시로 예정된 표결을 오후 5시로 앞당기는 방안이 거론됨.\n","- 국민의힘의 지연 전략에 대비해 시간 조정 논의.\n","\n","**5. 민주당의 우려와 대응**\n","- 민주당은 윤 대통령 측의 돌발 행동 가능성, 정치인 체포 시도 등 비상 상황을 우려.\n","- 신중하고 침착하게 대응하겠다는 입장.\n","\n","---\n","\n","**핵심 정리:**  \n","한동훈 국민의힘 대표가 윤 대통령 탄핵에 긍정적 입장을 내비치자, 민주당은 탄핵소추안 표결을 앞당기는 방안을 논의 중이나, 이재명 대표는 신중한 태도를 유지하고 있음. 민주당은 긴급 의원총회를 열고 비상 상황에 대비하고 있으며, 국민의힘의 지연 전략에 대응해 표결 시간을 조정할 가능성도 있음.\n","\n"," gpt-4o 토큰수:  199\n","gpt-4.1 토큰수:  830\n"]}]},{"cell_type":"code","source":["# 모델별 가격(2025년 6월 기준, 1M=1,000,000 토큰)\n","PRICING = {\n","    \"gpt-4.1\": {\n","        \"input\": 2.00,    # $2.00 / 1M input tokens\n","        \"output\": 8.00    # $8.00 / 1M output tokens\n","    },\n","    \"gpt-4.1-mini\": {\n","        \"input\": 0.40,    # $0.40 / 1M input tokens\n","        \"output\": 1.60    # $1.60 / 1M output tokens\n","    },\n","    \"gpt-4.1-nano\": {\n","        \"input\": 0.10,    # $0.10 / 1M input tokens\n","        \"output\": 0.40    # $0.40 / 1M output tokens\n","    },\n","    \"o1\": {\n","        \"input\": 2.00,    # $2.00 / 1M input tokens\n","        \"output\": 8.00    # $8.00 / 1M output tokens\n","    },\n","    \"o3\": {\n","        \"input\": 2.00,    # $2.00 / 1M input tokens\n","        \"output\": 8.00    # $8.00 / 1M output tokens\n","    },\n","    \"o4-mini\": {\n","        \"input\": 1.10,    # $1.10 / 1M input tokens\n","        \"output\": 4.40    # $4.40 / 1M output tokens\n","    },\n","    \"gpt-4o\": {\n","        \"input\": 2.50,    # $2.50 / 1M input tokens\n","        \"output\": 10.00   # $10.00 / 1M output tokens\n","    },\n","    \"gpt-4o-mini\": {\n","        \"input\": 0.15,    # $0.15 / 1M input tokens\n","        \"output\": 0.60    # $0.60 / 1M output tokens\n","    }\n","}\n","\n","def count_tokens(text, model):\n","    if model == 'gpt-4.1':\n","        encoding = tiktoken.get_encoding('cl100k_base')\n","    else:\n","        encoding = tiktoken.encoding_for_model(model)\n","    encoded = encoding.encode(text)\n","    return len(encoded)\n","\n","def calc_cost(input_text, output_text, model, num_service_call=1_000_000):\n","    input_tokens = count_tokens(input_text, model)\n","    output_tokens = count_tokens(output_text, model)\n","\n","    # 모델별 단가 가져오기\n","    price = PRICING[model]\n","\n","    # 비용계산\n","    input_cost = (input_tokens / 1_000_000) * price['input']\n","    output_cost = (output_tokens / 1_000_000) * price['output']\n","\n","    total_cost = (input_cost + output_cost) * num_service_call\n","    return total_cost\n","\n","print('$', calc_cost(text, output_gpt4o, model='gpt-4o-mini'))\n","print('$', calc_cost(text, output_gpt41, model='gpt-4.1'))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wesOyCN6aW_u","executionInfo":{"status":"ok","timestamp":1750832920375,"user_tz":-540,"elapsed":49,"user":{"displayName":"wars dream","userId":"01106558185160796091"}},"outputId":"34ab48f3-cbb7-48da-87a6-b1c5523d8fb4"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["$ 224.85\n","$ 9070.0\n"]}]}]}