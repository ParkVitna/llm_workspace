{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPXaGej3tS9gr/YONeMw8Ds"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Function calling\n","\n","https://platform.openai.com/docs/guides/function-calling\n","\n","<img src=\"https://cdn.openai.com/API/docs/images/function-calling-diagram-steps.png\" alt=\"Function Calling Diagram\" width=\"600\"/>\n","\n","Function Calling은 OpenAI의 GPT 모델이 특정 작업을 수행할 수 있도록 함수 호출을 지원하는 기능이다.\n","\n","이 기능을 활용하면 GPT 모델이 단순한 텍스트 생성뿐만 아니라 더 복잡한 작업도 자동으로 처리할 수 있다.\n","\n","Function Calling을 통해 다음과 같은 작업을 수행할 수 있다:\n","\n","1. **API 호출**: 외부 API를 호출하여 실시간 데이터를 가져오거나 특정 작업을 수행할 수 있다.  \n","   예) 날씨 정보 조회, 금융 데이터 조회\n","\n","2. **데이터 처리**: 특정 함수를 호출하여 데이터 처리 작업을 수행할 수 있다.  \n","   예) 텍스트 데이터 분석, 통계 계산\n","\n","3. **자동화된 작업**: 여러 단계의 작업을 자동화하여 수행할 수 있다.  \n","   예) 사용자가 요청한 내용을 기반으로 보고서 생성, 이메일 작성\n","\n","**주요 특징**\n","\n","- **함수 정의**: 사전에 정의된 함수나 API 엔드포인트를 GPT 모델에 통합할 수 있다.\n","- **자동 호출**: 사용자가 명시적으로 요청하지 않아도, GPT 모델이 컨텍스트를 이해하고 자동으로 적절한 함수를 호출할 수 있다.\n","- **입출력 처리**: 함수의 입력값을 자동으로 생성하고, 함수 호출 후 반환된 결과를 적절히 처리하여 사용자에게 전달할 수 있다."],"metadata":{"id":"XC4KYyyH4CIO"}},{"cell_type":"markdown","source":["## Function 정의"],"metadata":{"id":"9qUbna9O6ybX"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"p_uYlXYz36f9"},"outputs":[],"source":["# 날씨 API : https://openweathermap.org/\n","\n","\n","from google.colab import userdata\n","\n","OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n","OPENWEATHER_API_KEY = userdata.get('OPENWEATHER_API_KEY')"]},{"cell_type":"code","source":["import requests\n","import json\n","\n","def get_current_weather(city, units):\n","    url = f'https://api.openweathermap.org/data/2.5/weather?q={city}&appid={OPENWEATHER_API_KEY}&units={units}'\n","    response = requests.get(url)\n","    data = response.json()\n","\n","    # llm에 전달할 날씨정보\n","\n","    if response.status_code == 200:\n","      weather_description = data['weather'][0]['description']\n","      temperature = data['main']['temp']\n","      humidity = data['main']['humidity']\n","      weather_info = {'location': city, 'temperature': temperature, 'humidity': humidity, 'description': weather_description,\n","                      'unit': 'celsius' if units == 'metric' else 'fahrenheit'}\n","\n","    else:\n","      weather_info = {\n","          'location':city,\n","          'weather': 'Not Found',\n","          'temperature': 'Not Found',\n","          'humidity': 'Not Found',\n","          'unit': 'Not Found'\n","      }\n","    return json.dumps(weather_info)\n","\n","\n","\n","\n","get_current_weather('서초동', 'metric')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"_2aRtPmE_trj","executionInfo":{"status":"ok","timestamp":1750907869366,"user_tz":-540,"elapsed":86,"user":{"displayName":"정민영","userId":"01677110233997668601"}},"outputId":"b61d3583-5424-4a0b-e961-a3c94385bb38"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'{\"location\": \"\\\\uc11c\\\\ucd08\\\\ub3d9\", \"temperature\": 24.77, \"humidity\": 86, \"description\": \"overcast clouds\", \"unit\": \"celsius\"}'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":68}]},{"cell_type":"markdown","source":["## LLM 요청 흐름"],"metadata":{"id":"H6HsCbyCC8WJ"}},{"cell_type":"code","source":["from openai import OpenAI\n","\n","# LLM에게 각 function을 설명하는 메타정보\n","\n","\n","tools = [\n","    {\n","        \"type\": \"function\",\n","        \"function\": {\n","            \"name\": \"get_current_weather\",\n","            \"description\": \"주어진 도시에 대해 현재 날씨 정보를 가져옵니다.\",\n","            \"parameters\": {\n","                \"type\": \"object\",\n","                \"properties\": {\n","                    \"city\": {\n","                        \"type\": \"string\",\n","                        \"description\": \"날씨 정보를 얻고자 하는 도시명 혹은 지역명(영문)\"\n","                    },\n","                    \"units\": {\n","                        \"type\": \"string\",\n","                        \"enum\": [\"metric\", \"imperial\"],\n","                        \"description\": \"섭씨는 metric, 화씨는 imperial\"\n","                    }\n","                },\n","                \"required\": [\"city\", \"units\"],\n","                \"additionalProperties\": False\n","            }\n","        }\n","    }\n","]\n","\n","\n","\n","client = OpenAI(api_key = OPENAI_API_KEY)\n","\n","messages = [\n","    {'role': 'system', 'content': '당신은 친절한 챗봇으로, 사용자의 요청에 답변을 제공해주세요.'},\n","    {'role': 'user', 'content': '서울의 오늘 날씨를 알려줘'}\n","]\n","\n","response = client.chat.completions.create(\n","    model = 'gpt-4o-mini',\n","    messages=messages,\n","    tools=tools\n",")\n","\n","print(response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1tzevXR6C8HR","executionInfo":{"status":"ok","timestamp":1750908200073,"user_tz":-540,"elapsed":995,"user":{"displayName":"정민영","userId":"01677110233997668601"}},"outputId":"65359078-dd5f-47f5-f9d8-1f4b01e3d1b8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ChatCompletion(id='chatcmpl-BmXUm4xwdX3ppqYDGcN7ld0Gs4aKE', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_PxYY2WmMM4fVYN472JdJ1kr1', function=Function(arguments='{\"city\":\"Seoul\",\"units\":\"metric\"}', name='get_current_weather'), type='function')]))], created=1750908200, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_34a54ae93c', usage=CompletionUsage(completion_tokens=20, prompt_tokens=120, total_tokens=140, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"]}]},{"cell_type":"code","source":["# LLM으로부터 응답받은 function_call 정보\n","response_message = response.choices[0].message\n","tool_calls = response_message.tool_calls\n","tool_calls\n","print(response_message)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"19ESK24QC6fS","executionInfo":{"status":"ok","timestamp":1750908201626,"user_tz":-540,"elapsed":8,"user":{"displayName":"정민영","userId":"01677110233997668601"}},"outputId":"3ef2a52c-4ab9-4ef3-a47d-4d5b9c78f250"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_PxYY2WmMM4fVYN472JdJ1kr1', function=Function(arguments='{\"city\":\"Seoul\",\"units\":\"metric\"}', name='get_current_weather'), type='function')])\n"]}]},{"cell_type":"code","source":["# 함수목록에서 해당함수를 찾고 실행 - 실행결과를 다시 llm 질의\n","\n","# 실행가능한 함수목록\n","available_functions = {\n","    'get_current_weather': get_current_weather\n","}\n","\n","# llm(assistant): function_call 응답\n","messages.append(response_message) # 'role': 'assistant', 'tool_calls': ...\n","\n","for tool_call in tool_calls:\n","    function_name = tool_call.function.name\n","    function_to_call = available_functions[function_name]\n","    function_args = json.loads(tool_call.function.arguments) # json str -> dict\n","    # print(function_to_call)\n","    # print(function_args)\n","    function_response = function_to_call(**function_args)\n","    print(function_response)\n","\n","    messages.append({\n","        'role': 'tool',\n","        'tool_call_id': tool_call.id,\n","        'name': function_name,\n","        'content': function_response\n","    })\n","\n","messages"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BeBV_zj9IEio","executionInfo":{"status":"ok","timestamp":1750908221673,"user_tz":-540,"elapsed":77,"user":{"displayName":"정민영","userId":"01677110233997668601"}},"outputId":"fe4ef46d-6126-4bb0-a020-5f94d41a6c1c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{\"location\": \"Seoul\", \"temperature\": 23.76, \"humidity\": 94, \"description\": \"broken clouds\", \"unit\": \"celsius\"}\n"]},{"output_type":"execute_result","data":{"text/plain":["[{'role': 'system', 'content': '당신은 친절한 챗봇으로, 사용자의 요청에 답변을 제공해주세요.'},\n"," {'role': 'user', 'content': '서울의 오늘 날씨를 알려줘'},\n"," ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_PxYY2WmMM4fVYN472JdJ1kr1', function=Function(arguments='{\"city\":\"Seoul\",\"units\":\"metric\"}', name='get_current_weather'), type='function')]),\n"," {'role': 'tool',\n","  'tool_call_id': 'call_PxYY2WmMM4fVYN472JdJ1kr1',\n","  'name': 'get_current_weather',\n","  'content': '{\"location\": \"Seoul\", \"temperature\": 23.76, \"humidity\": 94, \"description\": \"broken clouds\", \"unit\": \"celsius\"}'}]"]},"metadata":{},"execution_count":95}]},{"cell_type":"code","source":["# 최종 llm 응답\n","response = client.chat.completions.create(\n","    model='gpt-4o-mini',\n","    messages=messages\n",")\n","\n","print(response.choices[0].message.content)"],"metadata":{"id":"D8TZOyzzIPK6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750908322675,"user_tz":-540,"elapsed":881,"user":{"displayName":"정민영","userId":"01677110233997668601"}},"outputId":"f54f3a8e-86c4-46b3-9ec1-2dac5daa4298"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["오늘 서울의 날씨는 다음과 같습니다:\n","- **온도**: 23.76도\n","- **습도**: 94%\n","- **상태**: 구름 많음\n","\n","편안한 하루 되세요!\n"]}]},{"cell_type":"code","source":["# tool_call을 포함한 함수\n","\n","\n","def run_conversation(prompt):\n","\n","  client = OpenAI(api_key = OPENAI_API_KEY)\n","\n","  messages = [\n","    {'role': 'system', 'content': '당신은 친절한 챗봇으로, 사용자의 요청에 답변을 제공해주세요.'},\n","    {'role': 'user', 'content': prompt}\n","]\n","\n","  # 첫 번째 LLM 요청\n","  response = client.chat.completions.create(\n","    model = 'gpt-4o-mini',\n","    messages=messages,\n","    tools=tools\n",")\n","  # 첫 번재 LLM 응답 확인\n","  response_message = response.choices[0].message\n","  tool_calls = response_message.tool_calls\n","\n","  if tool_calls:\n","    # llm (assistance): function_call 응답\n","    messages.append(response_message) # 'role': 'assistant', 'tool_calls': ...\n","\n","    for tool_call in tool_calls:\n","      function_name = tool_call.function.name\n","      function_to_call = available_functions[function_name]\n","      function_args = json.loads(tool_call.function.arguments) # json str -> dict\n","      function_response = function_to_call(**function_args)\n","\n","      messages.append({\n","        'role': 'tool',\n","        'tool_call_id': tool_call.id,\n","        'name': function_name,\n","        'content': function_response\n","    })\n","\n","      # 두 번째 LLM 요청\n","\n","      response = client.chat.completions.create(\n","      model='gpt-4o-mini',\n","      messages=messages\n",")\n","    return response.choices[0].message.content\n","\n","  else:\n","    return response_message.content\n","\n","\n","print(run_conversation(\"서울의 날씨를 알려줘\"))\n","print(run_conversation(\"오늘 밥 먹었니?\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":315},"id":"KSET6UNCUMSQ","executionInfo":{"status":"error","timestamp":1750984101218,"user_tz":-540,"elapsed":135,"user":{"displayName":"정민영","userId":"01677110233997668601"}},"outputId":"4f715cc4-34e8-4e68-f35c-0c0a76ee35c1"},"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'OpenAI' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1-8179500.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_conversation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"서울의 날씨를 알려줘\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_conversation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"오늘 밥 먹었니?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-1-8179500.py\u001b[0m in \u001b[0;36mrun_conversation\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_conversation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOPENAI_API_KEY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   messages = [\n","\u001b[0;31mNameError\u001b[0m: name 'OpenAI' is not defined"]}]},{"cell_type":"code","source":["import json\n","from openai import OpenAI\n","\n","def run_conversation(prompt):\n","    client = OpenAI(api_key=OPENAI_API_KEY)\n","\n","    messages = [\n","        {\"role\": \"system\", \"content\": \"당신은 친절한 챗봇입니다.\"},\n","        {\"role\": \"user\", \"content\": prompt}\n","    ]\n","\n","    # 1차 GPT 호출 → tool_call 요청 유도\n","    response = client.chat.completions.create(\n","        model=\"gpt-4o-mini\",\n","        messages=messages,\n","        tools=tools,\n","        tool_choice=\"auto\"\n","    )\n","\n","    response_message = response.choices[0].message\n","    tool_calls = response_message.tool_calls\n","\n","    if tool_calls:\n","        messages.append(response_message)  # assistant 메시지(tool_calls 포함)\n","\n","        for tool_call in tool_calls:\n","            function_name = tool_call.function.name\n","            function_to_call = available_functions[function_name]\n","            function_args = json.loads(tool_call.function.arguments)\n","            function_result = function_to_call(**function_args)\n","\n","            messages.append({\n","                \"role\": \"function\",  # ✅ 공식 role\n","                \"tool_call_id\": tool_call.id,\n","                \"name\": function_name,\n","                \"content\": json.dumps(function_result, ensure_ascii=False)  # ✅ 문자열화\n","            })\n","\n","        # GPT가 function 결과를 받아 최종 답변 생성\n","        final_response = client.chat.completions.create(\n","            model=\"gpt-4o-mini\",\n","            messages=messages\n","        )\n","        return final_response.choices[0].message.content\n","\n","    else:\n","        return response_message.content\n","\n","print(run_conversation(\"서울의 날씨를 알려줘\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":339},"id":"hGfEERlsWi-1","executionInfo":{"status":"error","timestamp":1750909738255,"user_tz":-540,"elapsed":1135,"user":{"displayName":"정민영","userId":"01677110233997668601"}},"outputId":"b56bcb70-98cd-43d7-9a03-6885ad6d2aa5"},"execution_count":null,"outputs":[{"output_type":"error","ename":"BadRequestError","evalue":"Error code: 400 - {'error': {'message': \"An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_xKsQHTvXoR2PaVrioifbV5FF\", 'type': 'invalid_request_error', 'param': 'messages.[3].role', 'code': None}}","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-117-1071385877.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_conversation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"서울의 날씨를 알려줘\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipython-input-117-1071385877.py\u001b[0m in \u001b[0;36mrun_conversation\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# GPT가 function 결과를 받아 최종 답변 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         final_response = client.chat.completions.create(\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-4o-mini\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/resources/chat/completions/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    923\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m    924\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    926\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             body=maybe_transform(\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1247\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m         )\n\u001b[0;32m-> 1249\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m     def patch(\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_xKsQHTvXoR2PaVrioifbV5FF\", 'type': 'invalid_request_error', 'param': 'messages.[3].role', 'code': None}}"]}]}]}