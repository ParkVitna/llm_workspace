{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPfpW1DFJkW+SyhRFuMdFtc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# STT Speech to Text\n","\n","## Whisper\n","\n","https://platform.openai.com/docs/models#whisper\n","\n","Whisper는 OpenAI에서 개발한 범용 음성 인식 모델로, 다양한 오디오 데이터셋을 학습하여 다국어 음성 인식, 음성 번역, 언어 식별 등의 작업을 수행할 수 있다.\n","\n","Whisper v2-large 모델은 현재 API를 통해 'whisper-1'이라는 이름으로 제공되고 있다.\n","\n","오픈 소스 버전의 Whisper와 API를 통한 Whisper는 기능적으로 동일하지만, API를 통해 제공되는 버전은 최적화된 추론 과정을 거쳐 다른 방법에 비해 더 빠르게 동작한다."],"metadata":{"id":"XVw_XpJa1SVY"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"IIM6D4xf1QWC","executionInfo":{"status":"ok","timestamp":1750835170702,"user_tz":-540,"elapsed":6394,"user":{"displayName":"김재아","userId":"11416159014926875591"}}},"outputs":[],"source":["from google.colab import userdata\n","\n","OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')"]},{"cell_type":"code","source":["from openai import OpenAI\n","\n","client = OpenAI(api_key=OPENAI_API_KEY)\n","file_path = 'output.mp3'\n","\n","with open(file_path, 'rb') as f:\n","  client.audio.transcriptions.create(\n","      model=\"whisper-1\",\n","      file=f,\n","      response_format=\"text\"\n","  )\n","print(file_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3YulZ-pW6HOK","executionInfo":{"status":"ok","timestamp":1750835471240,"user_tz":-540,"elapsed":2407,"user":{"displayName":"김재아","userId":"11416159014926875591"}},"outputId":"c21a3475-7dd9-40e1-f19f-fbbc23c2e0c5"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["output.mp3\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"ohxla7-s7NQC"},"execution_count":null,"outputs":[]}]}